# CUDAå†…å­˜ä¼˜åŒ–è¯¦è§£

## ğŸ” é—®é¢˜åˆ†æï¼šä¸ºä»€ä¹ˆç¬¬5ä¸ªEpochæ‰OOMï¼Ÿ

### åŸå§‹é”™è¯¯ä¿¡æ¯åˆ†æ
```
CUDA out of memory. Tried to allocate 4.15 GiB.
GPU 0 has a total capacity of 44.53 GiB
- Free: 3.84 GiB
- In use by process: 40.68 GiB
- Allocated by PyTorch: 36.78 GiB
- Reserved but unallocated: 3.56 GiB
```

### å…³é”®é—®é¢˜

#### 1. **ä¸ºä»€ä¹ˆå‰4ä¸ªepochæ­£å¸¸ï¼Œç¬¬5ä¸ªæ‰å´©æºƒï¼Ÿ**

**ä¸»è¦åŸå› ï¼šå†…å­˜ç´¯ç§¯æ•ˆåº”**

- **Epoch 1-2**: GPUç¼“å­˜åœ¨"å­¦ä¹ "æ•°æ®è®¿é—®æ¨¡å¼ï¼Œå†…å­˜ä½¿ç”¨é€æ¸å¢åŠ 
- **Epoch 3-4**: PyTorchç¼“å­˜åˆ†é…å™¨å¼€å§‹äº§ç”Ÿç¢ç‰‡ï¼Œä¿ç•™å†…å­˜å¢åŠ 
- **Epoch 5**: ç¢ç‰‡åŒ–ä¸¥é‡ + é‡åˆ°å¤§æ ·æœ¬ â†’ OOM

#### 2. **å†…å­˜æ³„æ¼çš„å…·ä½“æ¥æº**

```python
# âŒ é—®é¢˜ä»£ç 
def __getitem__(self, idx):
    data = torch.load(graph_path)  # æ¯æ¬¡éƒ½ä»ç£ç›˜åŠ è½½
    data.y = self.ligand_embeddings[key]  # ç›´æ¥å¼•ç”¨ï¼Œå¯èƒ½ä¿æŒå¼•ç”¨
    return data
```

**é—®é¢˜ï¼š**
- `torch.load()` æ¯æ¬¡è°ƒç”¨éƒ½ä¼šåˆ›å»ºæ–°çš„Pythonå¯¹è±¡å’ŒCUDA tensor
- é‡å¤è°ƒç”¨ä¼šè®©Pythonè§£é‡Šå™¨ä¿ç•™ä¸€äº›å†…éƒ¨çŠ¶æ€
- éšç€epochå¢åŠ ï¼Œè¿™äº›"å¹½çµ"å¼•ç”¨ç´¯ç§¯

#### 3. **PyTorchç¼“å­˜åˆ†é…å™¨çš„ç¢ç‰‡åŒ–**

PyTorchä½¿ç”¨ç¼“å­˜åˆ†é…å™¨æ¥æé«˜æ€§èƒ½ï¼š
- ä¸ä¼šç«‹å³é‡Šæ”¾GPUå†…å­˜ç»™OS
- ä¿ç•™å†…å­˜å—ä»¥å¤‡å¤ç”¨
- å¤šä¸ªepochåï¼Œå†…å­˜å˜å¾—ç¢ç‰‡åŒ–

```
Epoch 1:  [====] [====] [====]  (æ•´é½çš„å†…å­˜å—)
Epoch 3:  [==][=][===][=][==]  (å¼€å§‹ç¢ç‰‡åŒ–)
Epoch 5:  [=][==][=][=][===]  (ä¸¥é‡ç¢ç‰‡åŒ–ï¼Œæ— æ³•åˆ†é…å¤§å—)
```

#### 4. **DataLoaderçš„pin_memoryé™·é˜±**

```python
# âŒ åŸæ¥çš„é…ç½®
train_loader = DataLoader(
    dataset,
    num_workers=4,
    pin_memory=True  # æ¯ä¸ªworkeréƒ½ä¼šé¢„åŠ è½½æ•°æ®åˆ°å›ºå®šå†…å­˜
)
```

- `pin_memory=True` ä¼šå°†CPUæ•°æ®å›ºå®šåˆ°å†…å­˜ï¼Œå¿«é€Ÿä¼ è¾“åˆ°GPU
- ä½†ä¼šé¢å¤–å ç”¨ `batch_size Ã— num_workers` çš„å†…å­˜
- 4ä¸ªworkers Ã— batch_size=2 = åŒæ—¶8ä¸ªæ ·æœ¬å›ºå®šåœ¨å†…å­˜ä¸­

## âœ… å·²åº”ç”¨çš„ä¼˜åŒ–æ–¹æ¡ˆ

### 1. **ä¿®å¤æ•°æ®åŠ è½½å™¨çš„å†…å­˜æ³„æ¼**

```python
# âœ… ä¼˜åŒ–å
def __getitem__(self, idx):
    data = torch.load(graph_path, weights_only=False)

    # åˆ›å»ºæ–°tensorè€Œä¸æ˜¯ç›´æ¥å¼•ç”¨
    data.y = torch.tensor(ligand_embedding, dtype=torch.float32)

    return data
```

**æ”¹è¿›ï¼š**
- ä½¿ç”¨ `torch.tensor()` åˆ›å»ºç‹¬ç«‹å‰¯æœ¬
- é¿å…å…±äº«å¼•ç”¨å¯¼è‡´çš„å†…å­˜ä¿æŒ

### 2. **ä¼˜åŒ–è®­ç»ƒå¾ªç¯çš„å†…å­˜ç®¡ç†**

```python
# âœ… ä¼˜åŒ–åçš„è®­ç»ƒå¾ªç¯
for batch_idx, batch in enumerate(loader):
    batch = batch.to(device)

    # Forward & Backward
    pocket_embedding = model(batch)
    loss = F.mse_loss(pocket_embedding, target)
    loss.backward()
    optimizer.step()

    # è®°å½•losså€¼
    total_loss += loss.item()

    # â­ å…³é”®ï¼šæ˜¾å¼åˆ é™¤ä¸­é—´å˜é‡
    del pocket_embedding, target_embedding, loss

    # â­ æ¯10ä¸ªbatchæ¸…ç†ä¸€æ¬¡ç¼“å­˜ï¼ˆå¹³è¡¡æ€§èƒ½å’Œå†…å­˜ï¼‰
    if (batch_idx + 1) % 10 == 0:
        torch.cuda.empty_cache()
```

**æ”¹è¿›ï¼š**
- æ˜¾å¼ `del` åˆ é™¤ä¸­é—´å˜é‡ï¼Œç«‹å³é‡Šæ”¾å¼•ç”¨
- å‡å°‘ `empty_cache()` è°ƒç”¨é¢‘ç‡ï¼ˆåŸæ¥æ¯ä¸ªbatchï¼Œç°åœ¨æ¯10ä¸ªï¼‰
- é¿å…è¿‡åº¦è°ƒç”¨ `empty_cache()` çš„æ€§èƒ½æŸå¤±

### 3. **ä¼˜åŒ–DataLoaderé…ç½®**

```python
# âœ… ä¼˜åŒ–å
train_loader = DataLoader(
    dataset,
    batch_size=args.batch_size,
    shuffle=True,
    num_workers=min(args.num_workers, 2),  # é™åˆ¶æœ€å¤š2ä¸ªworker
    pin_memory=False,  # ç¦ç”¨pin_memoryèŠ‚çœå†…å­˜
    persistent_workers=False  # ä¸åœ¨epochä¹‹é—´ä¿æŒworkers
)
```

**æ”¹è¿›ï¼š**
- `num_workers=2`: å‡å°‘åŒæ—¶é¢„åŠ è½½çš„æ•°æ®é‡
- `pin_memory=False`: èŠ‚çœå›ºå®šå†…å­˜ï¼ˆå¯¹äºå°batchå½±å“ä¸å¤§ï¼‰
- `persistent_workers=False`: æ¯ä¸ªepochåå…³é—­workers

### 4. **Epochçº§åˆ«çš„å†…å­˜ç®¡ç†**

```python
# âœ… åœ¨epochå¼€å§‹å’Œç»“æŸæ—¶æ¸…ç†
for epoch in range(num_epochs):
    # Epochå¼€å§‹ï¼šæ¸…ç†ç¼“å­˜ + åŒæ­¥
    if device.type == 'cuda':
        torch.cuda.empty_cache()
        torch.cuda.synchronize()

    # è®­ç»ƒ...
    train_epoch(...)

    # éªŒè¯...
    evaluate(...)

    # Epochç»“æŸï¼šå†æ¬¡æ¸…ç†
    if device.type == 'cuda':
        torch.cuda.empty_cache()
```

**æ”¹è¿›ï¼š**
- `torch.cuda.synchronize()`: ç¡®ä¿æ‰€æœ‰CUDAæ“ä½œå®Œæˆ
- åœ¨epochè¾¹ç•Œæ¸…ç†ï¼Œå‡å°‘ç¢ç‰‡ç´¯ç§¯

## ğŸ“Š CUDAå†…å­˜ä½¿ç”¨çš„å…³é”®æ¦‚å¿µ

### 1. **PyTorchå†…å­˜åˆ†é…å™¨çš„ä¸‰å±‚ç»“æ„**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PyTorch Allocated Memory (36.78G)  â”‚  â† å®é™…åˆ†é…ç»™tensorçš„
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Reserved but Unallocated (3.56G)   â”‚  â† PyTorchç¼“å­˜æ± 
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Free GPU Memory (3.84G)            â”‚  â† OSå±‚é¢å¯ç”¨å†…å­˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Allocated**: tensorå®é™…å ç”¨çš„å†…å­˜
- **Reserved**: PyTorchç¼“å­˜èµ·æ¥çš„ï¼Œæ²¡è¿˜ç»™OS
- **Free**: çœŸæ­£å¯ç”¨çš„GPUå†…å­˜

### 2. **torch.cuda.empty_cache() çš„ä½œç”¨**

```python
torch.cuda.empty_cache()
```

- âŒ **ä¸ä¼š**é‡Šæ”¾tensorå ç”¨çš„å†…å­˜
- âœ… **ä¼š**å°†Reservedå†…å­˜è¿˜ç»™OS
- âš ï¸ **ä»£ä»·**ï¼šä¸‹æ¬¡åˆ†é…éœ€è¦é‡æ–°å‘OSç”³è¯·ï¼ˆæ…¢ï¼‰

**ä½•æ—¶ä½¿ç”¨ï¼š**
- Epochä¹‹é—´ï¼ˆå†…å­˜éœ€æ±‚å¯èƒ½å˜åŒ–ï¼‰
- æ‰¹é‡æ¨ç†åï¼ˆé‡Šæ”¾å¤§å—å†…å­˜ï¼‰
- âŒ ä¸è¦åœ¨æ¯ä¸ªbatchåä½¿ç”¨ï¼ˆæ€§èƒ½æŸå¤±å¤§ï¼‰

### 3. **å†…å­˜ç¢ç‰‡åŒ–ç¤ºæ„å›¾**

```
è‰¯å¥½çŠ¶æ€ï¼ˆEpoch 1ï¼‰:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Batch1 â”‚ Batch2 â”‚ Batch3 â”‚ Batch4 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ç¢ç‰‡åŒ–ï¼ˆEpoch 5ï¼‰:
â”Œâ”€â”€â”¬â”€â”¬â”€â”€â”€â”¬â”€â”¬â”€â”€â”¬â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”¬â”€â”¬â”€â”€â”€â”¬â”€â”€â”
â”‚B1â”‚ â”‚B2 â”‚ â”‚B3â”‚ â”‚B4  â”‚  â”‚ â”‚...â”‚  â”‚
â””â”€â”€â”´â”€â”´â”€â”€â”€â”´â”€â”´â”€â”€â”´â”€â”´â”€â”€â”€â”€â”´â”€â”€â”´â”€â”´â”€â”€â”€â”´â”€â”€â”˜
      â†‘ç©ºæ´         â†‘ç©ºæ´     â†‘ç©ºæ´

é—®é¢˜ï¼šå³ä½¿æ€»ç©ºé—²å†…å­˜è¶³å¤Ÿï¼Œä¹Ÿæ— æ³•åˆ†é…å¤§å—è¿ç»­å†…å­˜ï¼
```

### 4. **æ¢¯åº¦ç´¯ç§¯çš„å†…å­˜å½±å“**

```python
# æ¢¯åº¦ä¼šä¸€ç›´ä¿ç•™ç›´åˆ°optimizer.zero_grad()
loss.backward()  # åˆ›å»ºæ¢¯åº¦tensor
optimizer.step()  # ä½¿ç”¨æ¢¯åº¦
optimizer.zero_grad()  # â­ é‡Šæ”¾æ¢¯åº¦å†…å­˜
```

## ğŸš€ è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®

### 1. **ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯å‡å°batch size**

å¦‚æœä»ç„¶OOMï¼Œå¯ä»¥ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼š

```python
accumulation_steps = 4  # ç´¯ç§¯4ä¸ªbatchç›¸å½“äºbatch_size Ã— 4

for batch_idx, batch in enumerate(loader):
    loss = train_step(batch)
    loss = loss / accumulation_steps  # å¹³å‡æ¢¯åº¦
    loss.backward()

    if (batch_idx + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

**æ•ˆæœï¼š**
- batch_size=2, accumulation_steps=4 â†’ ç­‰æ•ˆbatch_size=8
- ä½†æ¯æ¬¡åªéœ€åŠ è½½2ä¸ªæ ·æœ¬çš„å†…å­˜

### 2. **æ··åˆç²¾åº¦è®­ç»ƒï¼ˆFP16ï¼‰**

```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for batch in loader:
    with autocast():  # è‡ªåŠ¨ä½¿ç”¨FP16
        output = model(batch)
        loss = criterion(output, target)

    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
    optimizer.zero_grad()
```

**æ•ˆæœï¼š**
- å†…å­˜ä½¿ç”¨å‡åŠï¼ˆFP16 vs FP32ï¼‰
- é€Ÿåº¦æå‡1.5-2x
- å‡ ä¹æ— ç²¾åº¦æŸå¤±ï¼ˆå¯¹äºå¤§å¤šæ•°ä»»åŠ¡ï¼‰

### 3. **ä½¿ç”¨gradient checkpointing**

```python
# åœ¨æ¨¡å‹ä¸­å¯ç”¨
from torch.utils.checkpoint import checkpoint

class MyModel(nn.Module):
    def forward(self, x):
        # ä¸ä¿å­˜ä¸­é—´æ¿€æ´»å€¼
        x = checkpoint(self.layer1, x)
        x = checkpoint(self.layer2, x)
        return x
```

**æ•ˆæœï¼š**
- å‡å°‘æ¿€æ´»å€¼å†…å­˜å ç”¨ï¼ˆ50-70%ï¼‰
- ä»£ä»·ï¼šåå‘ä¼ æ’­æ—¶éœ€è¦é‡æ–°è®¡ç®—ï¼ˆé€Ÿåº¦é™ä½20-30%ï¼‰

### 4. **ç›‘æ§å†…å­˜ä½¿ç”¨**

```python
def print_gpu_memory():
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        print(f"GPU Memory: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved")

# åœ¨å…³é”®ä½ç½®è°ƒç”¨
print_gpu_memory()  # Epochå¼€å§‹
train_epoch(...)
print_gpu_memory()  # Epochç»“æŸ
```

### 5. **ä½¿ç”¨ç¯å¢ƒå˜é‡ä¼˜åŒ–å†…å­˜åˆ†é…**

```bash
# å‡å°‘å†…å­˜ç¢ç‰‡åŒ–
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# åœ¨è„šæœ¬ä¸­è®¾ç½®
import os
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
```

## ğŸ¯ æ¨èçš„è®­ç»ƒé…ç½®

### å¯¹äº44GB GPUï¼ˆå¦‚A100ï¼‰ï¼š

```bash
python scripts/04_train_model.py \
    --batch_size 2 \              # ä¿æŒè¾ƒå°batch
    --num_workers 2 \              # é™åˆ¶workers
    --use_multi_hop \
    --use_nonbonded \
    --use_layer_norm \
    --num_epochs 300
```

### å¦‚æœä»ç„¶OOMï¼š

```bash
# æ–¹æ¡ˆ1ï¼šè¿›ä¸€æ­¥å‡å°batch size
--batch_size 1

# æ–¹æ¡ˆ2ï¼šä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
--batch_size 1 --gradient_accumulation_steps 4

# æ–¹æ¡ˆ3ï¼šä½¿ç”¨æ··åˆç²¾åº¦ï¼ˆéœ€è¦ä»£ç æ”¯æŒï¼‰
--use_amp
```

## ğŸ“ æ€»ç»“

### OOMçš„æ ¹æœ¬åŸå› ï¼š
1. âœ… **å†…å­˜æ³„æ¼**: `torch.load()` é‡å¤è°ƒç”¨ + å¼•ç”¨å…±äº«
2. âœ… **ç¼“å­˜ç¢ç‰‡åŒ–**: å¤šä¸ªepochåPyTorchç¼“å­˜æ± ç¢ç‰‡åŒ–
3. âœ… **DataLoaderé…ç½®**: è¿‡å¤šworkers + pin_memoryå ç”¨é¢å¤–å†…å­˜
4. âœ… **ç¼ºå°‘æ¸…ç†**: ä¸­é—´å˜é‡æ²¡æœ‰æ˜¾å¼é‡Šæ”¾

### å·²ä¿®å¤çš„å…³é”®ç‚¹ï¼š
- âœ… æ•°æ®åŠ è½½æ—¶åˆ›å»ºç‹¬ç«‹tensorå‰¯æœ¬
- âœ… æ˜¾å¼åˆ é™¤ä¸­é—´å˜é‡
- âœ… å‡å°‘workerså’Œç¦ç”¨pin_memory
- âœ… å‘¨æœŸæ€§æ¸…ç†CUDAç¼“å­˜
- âœ… Epochè¾¹ç•ŒåŒæ­¥å’Œæ¸…ç†

### å†…å­˜ä¼˜åŒ–ä¼˜å…ˆçº§ï¼š
1. **å¿…é¡»åš**: ä¿®å¤å†…å­˜æ³„æ¼ï¼ˆå·²å®Œæˆï¼‰
2. **åº”è¯¥åš**: ä¼˜åŒ–DataLoaderé…ç½®ï¼ˆå·²å®Œæˆï¼‰
3. **å¯é€‰åš**: æ··åˆç²¾åº¦è®­ç»ƒï¼ˆæ€§èƒ½æå‡ï¼‰
4. **æœ€åæ‰‹æ®µ**: Gradient checkpointingï¼ˆç‰ºç‰²é€Ÿåº¦ï¼‰

ç°åœ¨é‡æ–°è¿è¡Œè®­ç»ƒåº”è¯¥ä¸ä¼šå†OOMäº†ï¼
