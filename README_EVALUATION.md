# æ¨¡å‹è¯„ä¼° - å¿«é€Ÿå‚è€ƒ

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### è¯„ä¼°æµ‹è¯•é›†

```bash
# åŸºæœ¬ç”¨æ³•
python scripts/evaluate_test_set.py \
    --checkpoint models/checkpoints/best_model.pt

# å®Œæ•´å‚æ•°
python scripts/evaluate_test_set.py \
    --checkpoint models/checkpoints/best_model.pt \
    --splits data/splits/splits.json \
    --graph_dir data/processed/graphs \
    --ligand_embeddings data/processed/ligand_embeddings.h5 \
    --output results/test_evaluation.json \
    --metric cosine \
    --top_percentages 5 10 20
```

### è¿è¡Œç¤ºä¾‹è„šæœ¬

```bash
# è¿è¡Œé¢„é…ç½®çš„è¯„ä¼°ç¤ºä¾‹
./run_evaluation_example.sh
```

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | è¯´æ˜ |
|------|------|
| **Hit Rate @ top-k%** | æ­£ç¡®é…ä½“æ˜¯å¦åœ¨å‰k%å€™é€‰ä¸­ |
| **Mean Rank** | æ­£ç¡®é…ä½“çš„å¹³å‡æ’åï¼ˆè¶Šå°è¶Šå¥½ï¼‰ |
| **Median Rank** | æ­£ç¡®é…ä½“çš„ä¸­ä½æ•°æ’å |
| **Distance Statistics** | é¢„æµ‹ä¸æ­£ç¡®é…ä½“çš„è·ç¦»ç»Ÿè®¡ |

### å‘½ä¸­ç‡è®¡ç®—

- **top-5%**: æ­£ç¡®é…ä½“åœ¨å‰5%å€™é€‰ä¸­çš„æ¯”ä¾‹
- **top-10%**: æ­£ç¡®é…ä½“åœ¨å‰10%å€™é€‰ä¸­çš„æ¯”ä¾‹
- **top-20%**: æ­£ç¡®é…ä½“åœ¨å‰20%å€™é€‰ä¸­çš„æ¯”ä¾‹

**ç¤ºä¾‹**:
- é…ä½“åº“æœ‰1000ä¸ªé…ä½“
- top-5% = å‰50ä¸ªå€™é€‰
- å¦‚æœæ­£ç¡®é…ä½“æ’åâ‰¤50ï¼Œç®—ä½œå‘½ä¸­

## ğŸ“ è¾“å…¥æ–‡ä»¶

| æ–‡ä»¶ | è·¯å¾„ | è¯´æ˜ |
|------|------|------|
| **Checkpoint** | `models/checkpoints/best_model.pt` | è®­ç»ƒå¥½çš„æ¨¡å‹ |
| **Splits** | `data/splits/splits.json` | æ•°æ®é›†åˆ’åˆ†ï¼ˆtrain/val/testï¼‰ |
| **Graphs** | `data/processed/graphs/*.pt` | RNA pocketå›¾æ•°æ® |
| **Ligand Embeddings** | `data/processed/ligand_embeddings.h5` | é…ä½“embeddingsåº“ |

## ğŸ“¤ è¾“å‡ºç»“æœ

### ç»ˆç«¯è¾“å‡º

```
============================================================
Test Set Evaluation Results
============================================================

Total samples:           95
Successful predictions:  92
Failed predictions:      3

============================================================
Hit Rates
============================================================

  top5% (k=43):
  Hit rate:  45.65% (42/92)

 top10% (k=86):
  Hit rate:  68.48% (63/92)

 top20% (k=171):
  Hit rate:  84.78% (78/92)

============================================================
Rank Statistics (of correct ligand)
============================================================
  Mean rank:   65.32
  Median rank: 45.0
  Min rank:    1
  Max rank:    512
```

### JSONè¾“å‡º

ä¿å­˜è¯¦ç»†ç»“æœåˆ°JSONæ–‡ä»¶ï¼ˆä½¿ç”¨`--output`å‚æ•°ï¼‰ï¼š
- æ¯ä¸ªæ ·æœ¬çš„æ’åå’Œè·ç¦»
- å‘½ä¸­ç‡è¯¦ç»†ç»Ÿè®¡
- å¤±è´¥æ ·æœ¬ä¿¡æ¯

## ğŸ› ï¸ å¸¸ç”¨å‘½ä»¤

### 1. åŸºç¡€è¯„ä¼°
```bash
python scripts/evaluate_test_set.py \
    --checkpoint models/checkpoints/best_model.pt \
    --output results/eval.json
```

### 2. è‡ªå®šä¹‰é˜ˆå€¼
```bash
python scripts/evaluate_test_set.py \
    --checkpoint models/checkpoints/best_model.pt \
    --top_percentages 1 5 10 15 20 25 30
```

### 3. ä½¿ç”¨Euclideanè·ç¦»
```bash
python scripts/evaluate_test_set.py \
    --checkpoint models/checkpoints/best_model.pt \
    --metric euclidean
```

### 4. æ‰¹é‡è¯„ä¼°å¤šä¸ªcheckpoint
```bash
for ckpt in models/checkpoints/epoch_*.pt; do
    python scripts/evaluate_test_set.py \
        --checkpoint "$ckpt" \
        --output "results/$(basename $ckpt .pt)_eval.json"
done
```

## ğŸ” ç»“æœåˆ†æ

### æŸ¥çœ‹JSONç»“æœ

```python
import json

# åŠ è½½ç»“æœ
with open('results/test_evaluation.json', 'r') as f:
    results = json.load(f)

# æŸ¥çœ‹å‘½ä¸­ç‡
print(results['hit_rates'])

# æŸ¥çœ‹æ’åç»Ÿè®¡
print(results['rank_statistics'])

# æŸ¥çœ‹å›°éš¾æ ·æœ¬ï¼ˆæ’å>100ï¼‰
difficult = [r for r in results['detailed_results'] if r['rank'] > 100]
print(f"Difficult samples: {len(difficult)}")
```

### å¯è§†åŒ–

```python
import matplotlib.pyplot as plt
import numpy as np

# æ’ååˆ†å¸ƒ
ranks = [r['rank'] for r in results['detailed_results']]
plt.hist(ranks, bins=50)
plt.xlabel('Rank')
plt.ylabel('Count')
plt.title('Distribution of Correct Ligand Ranks')
plt.savefig('rank_distribution.png')
```

## ğŸ“‹ è¯„ä¼°æµç¨‹

1. **åŠ è½½æ¨¡å‹** â†’ è‡ªåŠ¨æ£€æµ‹ç‰ˆæœ¬å’Œé…ç½®
2. **åŠ è½½æµ‹è¯•é›†** â†’ ä»splits.jsonè¯»å–testéƒ¨åˆ†
3. **åŠ è½½é…ä½“åº“** â†’ åŠ è½½æ‰€æœ‰é…ä½“embeddings
4. **æ¨ç†é¢„æµ‹** â†’ å¯¹æ¯ä¸ªæµ‹è¯•æ ·æœ¬é¢„æµ‹embedding
5. **æ£€ç´¢æ’åº** â†’ è®¡ç®—è·ç¦»å¹¶æ’åº
6. **è®¡ç®—æŒ‡æ ‡** â†’ ç»Ÿè®¡æ’åå’Œå‘½ä¸­ç‡

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ•°æ®ä¸€è‡´æ€§**: ç¡®ä¿å›¾æ•°æ®å’Œembeddingsä¸è®­ç»ƒæ—¶ä¸€è‡´
2. **æ ‡å‡†åŒ–**: å¦‚æœè®­ç»ƒæ—¶ä½¿ç”¨äº†æ ‡å‡†åŒ–ï¼Œç¡®ä¿æµ‹è¯•æ•°æ®ä¹Ÿå·²æ ‡å‡†åŒ–
3. **æ¨¡å‹ç‰ˆæœ¬**: è„šæœ¬è‡ªåŠ¨æ£€æµ‹æ¨¡å‹ç‰ˆæœ¬ï¼ˆv1/v2ï¼‰
4. **å†…å­˜**: é…ä½“åº“è¾ƒå¤§æ—¶ä¼šå ç”¨è¾ƒå¤šå†…å­˜

## ğŸ’¡ å¸¸è§é—®é¢˜

**Q: ä¸ºä»€ä¹ˆæœ‰failed predictionsï¼Ÿ**
A: æ£€æŸ¥è¾“å‡ºä¸­çš„å¤±è´¥åŸå› ï¼Œå¯èƒ½æ˜¯æ–‡ä»¶ç¼ºå¤±æˆ–æ•°æ®æ ¼å¼é—®é¢˜

**Q: Cosine vs Euclideanè·ç¦»ï¼Ÿ**
A: Cosineè·ç¦»é€šå¸¸åœ¨embeddingæ£€ç´¢ä»»åŠ¡ä¸­è¡¨ç°æ›´å¥½ï¼ˆæ¨èä½¿ç”¨ï¼‰

**Q: å¦‚ä½•æé«˜å‘½ä¸­ç‡ï¼Ÿ**
A: å¢åŠ è®­ç»ƒæ•°æ®ã€è°ƒæ•´æ¨¡å‹æ¶æ„ã€æ”¹è¿›ç‰¹å¾å·¥ç¨‹ã€ä¼˜åŒ–è¶…å‚æ•°

**Q: Rank=1æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ**
A: è¡¨ç¤ºæ¨¡å‹å®Œç¾é¢„æµ‹ï¼Œæ­£ç¡®é…ä½“æ˜¯æœ€ç›¸ä¼¼çš„å€™é€‰

## ğŸ“š è¯¦ç»†æ–‡æ¡£

å®Œæ•´çš„è¯„ä¼°æŒ‡å—è¯·å‚è€ƒ: [EVALUATION_GUIDE.md](EVALUATION_GUIDE.md)

## ğŸ”— ç›¸å…³æ–‡ä»¶

- **è¯„ä¼°è„šæœ¬**: `scripts/evaluate_test_set.py`
- **è®­ç»ƒè„šæœ¬**: `scripts/04_train_model.py`
- **æ¨ç†è„šæœ¬**: `scripts/05_run_inference.py`
- **æ•°æ®åˆ’åˆ†**: `data/splits/splits.json`
- **ç¤ºä¾‹è„šæœ¬**: `run_evaluation_example.sh`

---

**å¿«é€Ÿå¸®åŠ©**: `python scripts/evaluate_test_set.py --help`
