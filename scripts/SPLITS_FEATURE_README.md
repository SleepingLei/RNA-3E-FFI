# æ•°æ®é›†åˆ†ç»„åŠŸèƒ½ï¼ˆDataset Splits Featureï¼‰

## åŠŸèƒ½æ¦‚è¿°

æ–°å¢äº†æ•°æ®é›†åˆ†ç»„é€‰æ‹©åŠŸèƒ½ï¼Œå¯ä»¥æ ¹æ® `data/splits/splits.json` é€‰æ‹©åˆ†æç‰¹å®šçš„æ•°æ®é›†ï¼ˆtrainã€valã€test æˆ–å®ƒä»¬çš„ç»„åˆï¼‰ã€‚

## å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ç”¨æ³•

```bash
# åˆ†ææµ‹è¯•é›†
bash scripts/run_embedding_analysis.sh \
    --splits_file data/splits/splits.json \
    --splits test

# åˆ†æéªŒè¯é›†å’Œæµ‹è¯•é›†
bash scripts/run_embedding_analysis.sh \
    --splits_file data/splits/splits.json \
    --splits "val test"

# åˆ†ææ‰€æœ‰æ•°æ®
bash scripts/run_embedding_analysis.sh \
    --splits_file data/splits/splits.json \
    --splits "train val test"
```

### Python è„šæœ¬ç”¨æ³•

```bash
# ä¸»å¯è§†åŒ–è„šæœ¬
python scripts/visualize_embeddings.py \
    --checkpoint models/checkpoints/best_model.pt \
    --graph_dir data/processed/graphs \
    --ligand_embeddings data/processed/ligand_embeddings_dedup.h5 \
    --output_dir results/test_analysis \
    --splits_file data/splits/splits.json \
    --splits test

# æŸ¥çœ‹å¸®åŠ©
python scripts/visualize_embeddings.py --help
```

## æ•°æ®é›†ç»Ÿè®¡

æ ¹æ® `data/splits/splits.json`ï¼š

| Split | æ ·æœ¬æ•° | å æ¯” |
|-------|--------|------|
| Train | 753    | 79.9% |
| Val   | 94     | 10.0% |
| Test  | 95     | 10.1% |
| Total | 942    | 100%  |

## ä½¿ç”¨åœºæ™¯

### 1. æ¨¡å‹æœ€ç»ˆè¯„ä¼°ï¼ˆæ¨èï¼‰

```bash
# åªåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°ï¼Œé¿å…è®­ç»ƒé›†æ³„æ¼
bash scripts/run_embedding_analysis.sh \
    --checkpoint models/checkpoints/best_model.pt \
    --splits_file data/splits/splits.json \
    --splits test \
    --output_dir results/final_evaluation

# æŸ¥çœ‹ç»“æœ
python scripts/view_analysis_summary.py \
    --results_dir results/final_evaluation
```

**ä¸ºä»€ä¹ˆæ¨èï¼Ÿ**
- é¿å…åœ¨è®­ç»ƒæ•°æ®ä¸Šè¯„ä¼°ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆçš„å‡è±¡ï¼‰
- ç¬¦åˆæœºå™¨å­¦ä¹ æœ€ä½³å®è·µ
- å¾—åˆ°çœŸå®çš„æ³›åŒ–æ€§èƒ½æŒ‡æ ‡

### 2. å¿«é€Ÿè¿­ä»£å¼€å‘

```bash
# åœ¨è¾ƒå°çš„éªŒè¯é›†ä¸Šå¿«é€Ÿæµ‹è¯•
bash scripts/run_embedding_analysis.sh \
    --splits_file data/splits/splits.json \
    --splits val \
    --output_dir results/dev_iteration
```

**ä¼˜åŠ¿ï¼š**
- éªŒè¯é›†åªæœ‰ 94 ä¸ªæ ·æœ¬ï¼Œè¿è¡Œé€Ÿåº¦å¿«
- å¯ä»¥å¿«é€Ÿè¿­ä»£è°ƒè¯•
- èŠ‚çœè®¡ç®—èµ„æº

### 3. è¿‡æ‹Ÿåˆæ£€æµ‹

```bash
# æ¯”è¾ƒè®­ç»ƒé›†å’Œæµ‹è¯•é›†æ€§èƒ½
bash scripts/run_embedding_analysis.sh \
    --splits_file data/splits/splits.json \
    --splits train \
    --output_dir results/train_perf

bash scripts/run_embedding_analysis.sh \
    --splits_file data/splits/splits.json \
    --splits test \
    --output_dir results/test_perf

# æ¯”è¾ƒå…³é”®æŒ‡æ ‡
echo "=== Train Set ==="
python scripts/view_analysis_summary.py \
    --results_dir results/train_perf \
    --sections retrieval | grep "Top-1"

echo "=== Test Set ==="
python scripts/view_analysis_summary.py \
    --results_dir results/test_perf \
    --sections retrieval | grep "Top-1"
```

**åˆ¤æ–­æ ‡å‡†ï¼š**
- å¦‚æœè®­ç»ƒé›† Top-1 = 90%ï¼Œæµ‹è¯•é›† Top-1 = 60% â†’ **ä¸¥é‡è¿‡æ‹Ÿåˆ**
- å¦‚æœè®­ç»ƒé›† Top-1 = 75%ï¼Œæµ‹è¯•é›† Top-1 = 70% â†’ **è½»å¾®è¿‡æ‹Ÿåˆï¼Œå¯æ¥å—**
- å¦‚æœè®­ç»ƒé›† Top-1 = 70%ï¼Œæµ‹è¯•é›† Top-1 = 72% â†’ **è‰¯å¥½æ³›åŒ–**

### 4. æ¨¡å‹ç‰ˆæœ¬æ¯”è¾ƒ

```bash
# åœ¨æµ‹è¯•é›†ä¸Šæ¯”è¾ƒä¸åŒè®­ç»ƒé˜¶æ®µçš„æ¨¡å‹
for epoch in 50 100 150 200; do
    bash scripts/run_embedding_analysis.sh \
        --checkpoint models/checkpoints/epoch_${epoch}.pt \
        --splits_file data/splits/splits.json \
        --splits test \
        --output_dir results/epoch_${epoch}_test
done

# ç”Ÿæˆæ€§èƒ½å¯¹æ¯”è¡¨
echo "Epoch,Top1,Top5,Top10,MRR" > results/model_comparison.csv
for epoch in 50 100 150 200; do
    echo -n "$epoch," >> results/model_comparison.csv
    python scripts/view_analysis_summary.py \
        --results_dir results/epoch_${epoch}_test \
        --sections retrieval | grep "Top-" | awk '{print $2}' | tr '\n' ',' >> results/model_comparison.csv
    echo "" >> results/model_comparison.csv
done
```

### 5. äº¤å‰éªŒè¯åˆ†æ

```bash
# åˆ†åˆ«åœ¨ val å’Œ test ä¸Šè¯„ä¼°ï¼ŒéªŒè¯ç¨³å®šæ€§
bash scripts/run_embedding_analysis.sh \
    --splits_file data/splits/splits.json \
    --splits val \
    --output_dir results/val_eval

bash scripts/run_embedding_analysis.sh \
    --splits_file data/splits/splits.json \
    --splits test \
    --output_dir results/test_eval

# å¦‚æœ val å’Œ test æ€§èƒ½æ¥è¿‘ï¼Œè¯´æ˜æ¨¡å‹ç¨³å®š
```

## æŠ€æœ¯ç»†èŠ‚

### å·¥ä½œåŸç†

1. **åŠ è½½ splits.json**ï¼šè¯»å–æŒ‡å®šåˆ†ç»„çš„ complex ID åˆ—è¡¨
2. **è¿‡æ»¤ graph æ–‡ä»¶**ï¼šåªä¿ç•™åœ¨æŒ‡å®šåˆ†ç»„ä¸­çš„ graph æ–‡ä»¶
3. **æ¨ç†å’Œåˆ†æ**ï¼šå¯¹è¿‡æ»¤åçš„æ•°æ®è¿›è¡Œå®Œæ•´çš„æ¨ç†å’Œåˆ†ææµç¨‹

### æ–‡ä»¶åŒ¹é…

è„šæœ¬é€šè¿‡æ–‡ä»¶åï¼ˆå»é™¤ .pt æ‰©å±•åï¼‰ä¸ splits.json ä¸­çš„ ID è¿›è¡ŒåŒ¹é…ï¼š

```python
# splits.json
{
  "test": [
    "1aju_ARG_model0",  # â† è¿™ä¸ª ID
    "2kx8_GTP_model1",
    ...
  ]
}

# Graph æ–‡ä»¶
data/processed/graphs/1aju_ARG_model0.pt  # â† åŒ¹é…è¿™ä¸ªæ–‡ä»¶
```

### ä»£ç å®ç°

æ ¸å¿ƒå‡½æ•°ä½äº `scripts/visualize_embeddings.py`:

```python
def load_splits(splits_file, split_names):
    """åŠ è½½æ•°æ®é›†åˆ†ç»„"""
    with open(splits_file, 'r') as f:
        splits_data = json.load(f)

    selected_ids = set()
    for split_name in split_names:
        if split_name in splits_data:
            selected_ids.update(splits_data[split_name])

    return selected_ids

def batch_inference_with_metadata(..., selected_ids=None):
    """æ‰¹é‡æ¨ç†ï¼Œæ”¯æŒ split è¿‡æ»¤"""
    graph_files = Path(graph_dir).glob("*.pt")

    if selected_ids is not None:
        graph_files = [f for f in graph_files if f.stem in selected_ids]

    # ç»§ç»­æ¨ç†...
```

## å‚æ•°è¯´æ˜

### --splits_file

- **ç±»å‹**: å­—ç¬¦ä¸²ï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰
- **å¿…éœ€**: å¦ï¼ˆé»˜è®¤ä¸ä½¿ç”¨ splitsï¼‰
- **è¯´æ˜**: splits.json æ–‡ä»¶çš„è·¯å¾„
- **ç¤ºä¾‹**: `data/splits/splits.json`

### --splits

- **ç±»å‹**: å­—ç¬¦ä¸²åˆ—è¡¨
- **å¿…éœ€**: å¦ï¼ˆé»˜è®¤ä¸ä½¿ç”¨ splitsï¼‰
- **å¯é€‰å€¼**: `train`, `val`, `test`ï¼ˆå¯å¤šé€‰ï¼‰
- **è¯´æ˜**: è¦åˆ†æçš„æ•°æ®é›†åˆ†ç»„
- **ç¤ºä¾‹**:
  - å•ä¸ª: `--splits test`
  - å¤šä¸ª: `--splits "val test"`
  - å…¨éƒ¨: `--splits "train val test"`

**æ³¨æ„**ï¼šå¿…é¡»åŒæ—¶æŒ‡å®š `--splits_file` å’Œ `--splits` æ‰ä¼šå¯ç”¨è¿‡æ»¤ã€‚

## éªŒè¯å’Œæµ‹è¯•

### æµ‹è¯•è„šæœ¬

```bash
# è¿è¡Œæµ‹è¯•è„šæœ¬ï¼ŒéªŒè¯åŠŸèƒ½æ­£å¸¸
python scripts/test_splits_functionality.py
```

æµ‹è¯•å†…å®¹ï¼š
- âœ“ åŠ è½½ splits.json
- âœ“ éªŒè¯æ–‡ä»¶ç»“æ„
- âœ“ æµ‹è¯•ä¸åŒç»„åˆ
- âœ“ æ£€æŸ¥ä¸ graph æ–‡ä»¶çš„åŒ¹é…æƒ…å†µ

### é¢„æœŸè¾“å‡º

```
Split Statistics:
  train   :  753 samples
  val     :   94 samples
  test    :   95 samples
  Total   :  942 samples

Testing Split Combinations:
  Train only          :  753 samples
  Val only            :   94 samples
  Test only           :   95 samples
  Val + Test          :  189 samples
  Train + Val         :  847 samples
  All splits          :  942 samples

âœ“ All tests passed!
```

## å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆåŒ¹é…ä¸åˆ°ä»»ä½•æ–‡ä»¶ï¼Ÿ

**A**: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. splits.json çš„è·¯å¾„æ˜¯å¦æ­£ç¡®
2. graph æ–‡ä»¶ç›®å½•æ˜¯å¦æ­£ç¡®
3. ID æ ¼å¼æ˜¯å¦åŒ¹é…ï¼ˆå¤§å°å†™æ•æ„Ÿï¼‰
4. graph æ–‡ä»¶åæ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆåº”è¯¥æ˜¯ `{id}.pt`ï¼‰

### Q2: å¯ä»¥è‡ªå®šä¹‰ splits.json å—ï¼Ÿ

**A**: å¯ä»¥ï¼æ ¼å¼å¦‚ä¸‹ï¼š

```json
{
  "my_custom_split": [
    "complex_id_1",
    "complex_id_2",
    ...
  ]
}
```

ç„¶åä½¿ç”¨ï¼š
```bash
--splits_file your_splits.json --splits my_custom_split
```

### Q3: ä¸ä½¿ç”¨ splits åŠŸèƒ½ä¼šæ€æ ·ï¼Ÿ

**A**: å¦‚æœä¸æŒ‡å®š `--splits_file` å’Œ `--splits`ï¼Œè„šæœ¬ä¼šå¤„ç† graph_dir ä¸­çš„æ‰€æœ‰ .pt æ–‡ä»¶ï¼Œä¸ä¹‹å‰çš„è¡Œä¸ºå®Œå…¨ä¸€è‡´ã€‚

### Q4: å¯ä»¥æ··åˆä½¿ç”¨å¤šä¸ª split å—ï¼Ÿ

**A**: å¯ä»¥ï¼ä½¿ç”¨ç©ºæ ¼åˆ†éš”ï¼š

```bash
--splits "train val test"  # åˆ†æå…¨éƒ¨æ•°æ®
--splits "val test"        # åˆ†æ val + test
```

### Q5: å¦‚ä½•ç¡®è®¤è¿‡æ»¤æ˜¯å¦ç”Ÿæ•ˆï¼Ÿ

**A**: æŸ¥çœ‹è¾“å‡ºæ—¥å¿—ï¼š

```
Found 942 pocket graphs in data/processed/graphs
Filtered to 95 graphs based on split selection (removed 847)
```

## æ€§èƒ½è€ƒè™‘

### æ•°æ®é‡å¯¹æ¯”

| é…ç½® | æ ·æœ¬æ•° | é¢„è®¡æ—¶é—´* |
|------|--------|----------|
| å…¨éƒ¨æ•°æ® | 942 | ~15-30 åˆ†é’Ÿ |
| è®­ç»ƒé›† | 753 | ~12-25 åˆ†é’Ÿ |
| éªŒè¯é›† | 94 | ~2-5 åˆ†é’Ÿ |
| æµ‹è¯•é›† | 95 | ~2-5 åˆ†é’Ÿ |
| Val+Test | 189 | ~4-8 åˆ†é’Ÿ |

*æ—¶é—´ä¼°è®¡å–å†³äºç¡¬ä»¶é…ç½®å’Œæ˜¯å¦ä½¿ç”¨ GPU

### ä¼˜åŒ–å»ºè®®

1. **å¼€å‘é˜¶æ®µ**: ä½¿ç”¨ `--splits val` å¿«é€Ÿè¿­ä»£
2. **æœ€ç»ˆè¯„ä¼°**: ä½¿ç”¨ `--splits test` è·å–çœŸå®æ€§èƒ½
3. **å®Œæ•´åˆ†æ**: ä½¿ç”¨ `--splits "train val test"` æˆ–ä¸æŒ‡å®š splits

## ç›¸å…³æ–‡ä»¶

- `scripts/visualize_embeddings.py` - ä¸»å¯è§†åŒ–è„šæœ¬ï¼ˆåŒ…å« splits åŠŸèƒ½ï¼‰
- `scripts/run_embedding_analysis.sh` - ä¸€é”®è¿è¡Œè„šæœ¬
- `scripts/test_splits_functionality.py` - æµ‹è¯•è„šæœ¬
- `scripts/QUICKSTART_visualization.md` - å¿«é€Ÿå…¥é—¨æŒ‡å—
- `data/splits/splits.json` - æ•°æ®é›†åˆ†ç»„æ–‡ä»¶

## æ›´æ–°æ—¥å¿—

### v1.1.0 (å½“å‰ç‰ˆæœ¬)
- âœ¨ æ–°å¢æ•°æ®é›†åˆ†ç»„é€‰æ‹©åŠŸèƒ½
- âœ¨ æ”¯æŒ train/val/test ä»»æ„ç»„åˆ
- âœ¨ æ·»åŠ  `--splits_file` å’Œ `--splits` å‚æ•°
- ğŸ“ æ›´æ–°æ–‡æ¡£å’Œç¤ºä¾‹
- âœ… æ·»åŠ æµ‹è¯•è„šæœ¬

### v1.0.0 (åŸå§‹ç‰ˆæœ¬)
- âœ¨ åŸºç¡€å¯è§†åŒ–å’Œåˆ†æåŠŸèƒ½
- âœ¨ PCA/t-SNE/UMAP é™ç»´
- âœ¨ æ£€ç´¢æ€§èƒ½è¯„ä¼°
- âœ¨ èšç±»åˆ†æ

## è´¡çŒ®

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æŸ¥é˜…ï¼š
- è¯¦ç»†æ–‡æ¡£: `scripts/README_embedding_visualization.md`
- å¿«é€Ÿå…¥é—¨: `scripts/QUICKSTART_visualization.md`
- ä¸»è„šæœ¬: `scripts/visualize_embeddings.py`

---

**Happy Analyzing! ğŸ‰**
