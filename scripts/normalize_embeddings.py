#!/usr/bin/env python3
"""
Normalize Existing Ligand Embeddings

This script takes an existing HDF5 file containing ligand embeddings
(generated by scripts/02_embed_ligands.py) and applies z-score normalization.

Usage:
    python scripts/normalize_embeddings.py --input data/processed/ligand_embeddings.h5
    python scripts/normalize_embeddings.py --input embeddings.h5 --output embeddings_normalized.h5
    python scripts/normalize_embeddings.py --input embeddings.h5 --inplace
"""
import argparse
import h5py
import numpy as np
from pathlib import Path
from tqdm import tqdm


def normalize_h5_embeddings(input_h5_path, output_h5_path=None, params_output_path=None, inplace=False):
    """
    Normalize all embeddings in an HDF5 file using z-score normalization.

    Args:
        input_h5_path: Path to input HDF5 file with embeddings
        output_h5_path: Path to output HDF5 file (if None, will append '_normalized' to input)
        params_output_path: Path to save normalization parameters (if None, saves next to output)
        inplace: If True, overwrite the input file (ignores output_h5_path)

    Returns:
        Tuple of (output_path, params_path)
    """
    input_h5_path = Path(input_h5_path)

    if not input_h5_path.exists():
        raise FileNotFoundError(f"Input HDF5 file not found: {input_h5_path}")

    # Determine output paths
    if inplace:
        output_h5_path = input_h5_path
        print(f"⚠️  WARNING: In-place mode enabled. Original file will be overwritten!")
    elif output_h5_path is None:
        # Default: add '_normalized' suffix
        output_h5_path = input_h5_path.parent / f"{input_h5_path.stem}_normalized{input_h5_path.suffix}"
    else:
        output_h5_path = Path(output_h5_path)

    if params_output_path is None:
        # Save normalization params next to output file
        params_output_path = output_h5_path.parent / "ligand_embedding_norm_params.npz"
    else:
        params_output_path = Path(params_output_path)

    # Ensure output directory exists
    output_h5_path.parent.mkdir(parents=True, exist_ok=True)
    params_output_path.parent.mkdir(parents=True, exist_ok=True)

    print(f"\n{'='*60}")
    print(f"Normalizing Ligand Embeddings")
    print(f"{'='*60}\n")
    print(f"Input:  {input_h5_path}")
    print(f"Output: {output_h5_path}")
    print(f"Params: {params_output_path}")
    print()

    # Step 1: Load all embeddings from HDF5
    print("Step 1: Loading embeddings from HDF5...")
    embeddings_dict = {}
    complex_ids = []

    with h5py.File(input_h5_path, 'r') as f:
        total_keys = len(f.keys())
        print(f"Found {total_keys} embeddings in file")

        for complex_id in tqdm(f.keys(), desc="Loading embeddings"):
            embedding = np.array(f[complex_id][:])
            embeddings_dict[complex_id] = embedding
            complex_ids.append(complex_id)

    if len(embeddings_dict) == 0:
        raise ValueError(f"No embeddings found in {input_h5_path}")

    print(f"✓ Loaded {len(embeddings_dict)} embeddings")

    # Step 2: Compute normalization parameters
    print("\nStep 2: Computing normalization parameters...")

    # Stack all embeddings into a matrix
    all_embeddings = np.array(list(embeddings_dict.values()))
    print(f"Embeddings shape: {all_embeddings.shape}")
    print(f"  Number of embeddings: {all_embeddings.shape[0]}")
    print(f"  Embedding dimension:  {all_embeddings.shape[1]}")

    # Compute global statistics across all embeddings
    embedding_mean = np.mean(all_embeddings, axis=0, keepdims=True)
    embedding_std = np.std(all_embeddings, axis=0, keepdims=True)

    # Add small epsilon to avoid division by zero
    epsilon = 1e-8
    embedding_std = np.where(embedding_std < epsilon, 1.0, embedding_std)

    print(f"✓ Computed normalization parameters")
    print(f"  Mean range: [{embedding_mean.min():.4f}, {embedding_mean.max():.4f}]")
    print(f"  Std range:  [{embedding_std.min():.4f}, {embedding_std.max():.4f}]")

    # Check for potential issues
    constant_dims = np.sum(embedding_std.squeeze() == 1.0)
    if constant_dims > 0:
        print(f"  ⚠️  Warning: {constant_dims} dimensions have constant values (std < {epsilon})")

    # Step 3: Save normalization parameters
    print(f"\nStep 3: Saving normalization parameters to {params_output_path}...")
    np.savez(params_output_path,
             mean=embedding_mean.squeeze(),
             std=embedding_std.squeeze())
    print(f"✓ Saved normalization parameters")

    # Step 4: Apply normalization to all embeddings
    print("\nStep 4: Applying normalization to all embeddings...")

    normalized_embeddings = {}
    for complex_id in tqdm(complex_ids, desc="Normalizing"):
        embedding = embeddings_dict[complex_id]
        normalized = (embedding - embedding_mean.squeeze()) / embedding_std.squeeze()
        normalized_embeddings[complex_id] = normalized

    print(f"✓ Normalized {len(normalized_embeddings)} embeddings")

    # Verify normalization
    all_normalized = np.array(list(normalized_embeddings.values()))
    print(f"\nVerification:")
    print(f"  Normalized mean: {np.mean(all_normalized, axis=0).mean():.6f} (should be ~0)")
    print(f"  Normalized std:  {np.std(all_normalized, axis=0).mean():.6f} (should be ~1)")

    # Step 5: Save normalized embeddings to HDF5
    if inplace:
        # For in-place, use a temporary file then rename
        print(f"\nStep 5: Saving normalized embeddings (in-place)...")
        temp_output = output_h5_path.parent / f"{output_h5_path.stem}_temp{output_h5_path.suffix}"

        with h5py.File(temp_output, 'w') as f:
            for complex_id, embedding in tqdm(normalized_embeddings.items(), desc="Writing to HDF5"):
                f.create_dataset(complex_id, data=embedding)

        # Replace original file
        import shutil
        shutil.move(str(temp_output), str(output_h5_path))
        print(f"✓ Overwritten original file: {output_h5_path}")

    else:
        print(f"\nStep 5: Saving normalized embeddings to {output_h5_path}...")
        with h5py.File(output_h5_path, 'w') as f:
            for complex_id, embedding in tqdm(normalized_embeddings.items(), desc="Writing to HDF5"):
                f.create_dataset(complex_id, data=embedding)
        print(f"✓ Saved normalized embeddings")

    print(f"\n{'='*60}")
    print(f"Normalization Complete!")
    print(f"{'='*60}")
    print(f"\nOutput files:")
    print(f"  Normalized embeddings: {output_h5_path}")
    print(f"  Normalization params:  {params_output_path}")
    print(f"\nYou can now use these files for training.")
    print(f"The normalization parameters will be used during inference/testing.")

    return output_h5_path, params_output_path


def inspect_h5_file(h5_path):
    """
    Inspect an HDF5 file and print basic statistics.

    Args:
        h5_path: Path to HDF5 file
    """
    h5_path = Path(h5_path)

    if not h5_path.exists():
        raise FileNotFoundError(f"HDF5 file not found: {h5_path}")

    print(f"\n{'='*60}")
    print(f"Inspecting HDF5 File: {h5_path}")
    print(f"{'='*60}\n")

    with h5py.File(h5_path, 'r') as f:
        num_embeddings = len(f.keys())
        print(f"Number of embeddings: {num_embeddings}")

        if num_embeddings > 0:
            # Get first embedding to check dimensions
            first_key = list(f.keys())[0]
            first_embedding = np.array(f[first_key][:])
            embedding_dim = first_embedding.shape[0] if len(first_embedding.shape) == 1 else first_embedding.shape

            print(f"Embedding dimension:  {embedding_dim}")

            # Sample some embeddings to compute statistics
            sample_size = min(100, num_embeddings)
            sample_embeddings = []

            for i, key in enumerate(f.keys()):
                if i >= sample_size:
                    break
                sample_embeddings.append(np.array(f[key][:]))

            sample_embeddings = np.array(sample_embeddings)

            # Compute statistics
            mean = np.mean(sample_embeddings)
            std = np.std(sample_embeddings)
            min_val = np.min(sample_embeddings)
            max_val = np.max(sample_embeddings)

            print(f"\nStatistics (from {sample_size} samples):")
            print(f"  Mean: {mean:.6f}")
            print(f"  Std:  {std:.6f}")
            print(f"  Min:  {min_val:.6f}")
            print(f"  Max:  {max_val:.6f}")

            # Check if data appears normalized
            is_normalized = abs(mean) < 0.1 and abs(std - 1.0) < 0.2
            print(f"\nAppears normalized: {'✓ Yes' if is_normalized else '✗ No'}")

            # Show some example keys
            print(f"\nExample complex IDs:")
            for i, key in enumerate(list(f.keys())[:5]):
                print(f"  {i+1}. {key}")
            if num_embeddings > 5:
                print(f"  ... and {num_embeddings - 5} more")

    print(f"\n{'='*60}\n")


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Normalize existing ligand embeddings in HDF5 format",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Normalize and create new file (default)
  python scripts/normalize_embeddings.py --input data/processed/ligand_embeddings.h5

  # Normalize and specify output file
  python scripts/normalize_embeddings.py --input embeddings.h5 --output embeddings_norm.h5

  # Normalize in-place (overwrite original file)
  python scripts/normalize_embeddings.py --input embeddings.h5 --inplace

  # Just inspect the file without normalizing
  python scripts/normalize_embeddings.py --input embeddings.h5 --inspect-only

  # Specify custom location for normalization parameters
  python scripts/normalize_embeddings.py --input embeddings.h5 --params-output params.npz
        """
    )

    parser.add_argument("--input", type=str, required=True,
                        help="Path to input HDF5 file with embeddings")
    parser.add_argument("--output", type=str, default=None,
                        help="Path to output HDF5 file (default: input_normalized.h5)")
    parser.add_argument("--params-output", type=str, default=None,
                        help="Path to save normalization parameters (default: ligand_embedding_norm_params.npz)")
    parser.add_argument("--inplace", action="store_true",
                        help="Overwrite input file instead of creating new file")
    parser.add_argument("--inspect-only", action="store_true",
                        help="Only inspect the file, don't normalize")

    args = parser.parse_args()

    try:
        if args.inspect_only:
            # Just inspect the file
            inspect_h5_file(args.input)
        else:
            # Normalize the embeddings
            output_path, params_path = normalize_h5_embeddings(
                input_h5_path=args.input,
                output_h5_path=args.output,
                params_output_path=args.params_output,
                inplace=args.inplace
            )

            # Optionally inspect the normalized output
            print("\n" + "="*60)
            print("Verifying normalized output...")
            print("="*60)
            inspect_h5_file(output_path)

    except Exception as e:
        print(f"\n❌ Error: {e}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
