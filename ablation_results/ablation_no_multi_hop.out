nohup: ignoring input
==========================================
Training with Memory Optimization
==========================================
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(

Starting distributed training with 4 GPUs...
Spawning processes...

/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
[rank1]:[W1111 23:13:05.095602483 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank3]:[W1111 23:13:06.193381796 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank2]:[W1111 23:13:06.263351115 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank0]:[W1111 23:13:06.287436575 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
/personal/RNA-3E-FFI/scripts/04_train_model.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(graph_path)
/personal/RNA-3E-FFI/scripts/04_train_model.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(graph_path)
/personal/RNA-3E-FFI/scripts/04_train_model.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(graph_path)
/personal/RNA-3E-FFI/scripts/04_train_model.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(graph_path)
/opt/mamba/envs/RNA/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/mamba/envs/RNA/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/mamba/envs/RNA/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Dataset initialized with 954 valid complexes
Dataset initialized with 117 valid complexes
Using pooling type: multihead_attention
/opt/mamba/envs/RNA/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Training:   0%|          | 0/30 [00:00<?, ?it/s]Dataset initialized with 954 valid complexes
Dataset initialized with 117 valid complexes
Using pooling type: multihead_attention
Dataset initialized with 954 valid complexes
Dataset initialized with 117 valid complexes
Using pooling type: multihead_attention
Using device: cuda:0
Distributed training with 4 GPUs
Loading splits from data/splits/filtered_splits.json
Dataset splits: Train=954, Val=117, Test=122
Dataset initialized with 954 valid complexes
Dataset initialized with 117 valid complexes

Initializing v3.0 model (with V3 improvements)...
Using RNAPocketEncoderV3 (geometric MP + enhanced invariants)
  Geometric MP: True
  Enhanced invariants: True (204-dim vs 56-dim)
  Improved layers: True (Bessel+Cutoff+ImprovedMP)
  Norm type: layer
  Attention heads: 8
  Initial angle weight: 0.500
  Initial dihedral weight: 0.500
  Initial nonbonded weight: 1.000
Using pooling type: multihead_attention
Model has 3,183,661 parameters

Model configuration:
  Multi-hop: False
  Non-bonded: True
  Pooling: attention
  Initial nonbonded weight: 0.990

Starting training from scratch...


============================================================
Training Configuration
============================================================
Batch Size per GPU: 8
Number of GPUs: 4
Effective Batch Size: 32

Mixed Precision Training (AMP): Disabled

Loss Function: mse

Gradient Clipping: 2.0 (manual)
Gradient Monitoring: ENABLED (will print every 50 batches)
============================================================

Starting training...

Epoch 1/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:08<03:57,  8.20s/it]Training:   3%|â–Ž         | 1/30 [00:08<03:57,  8.20s/it]Training:   3%|â–Ž         | 1/30 [00:08<03:57,  8.20s/it]Training:   3%|â–Ž         | 1/30 [00:08<03:57,  8.20s/it]Training:   7%|â–‹         | 2/30 [00:09<02:01,  4.33s/it]Training:   7%|â–‹         | 2/30 [00:09<02:01,  4.33s/it]Training:   7%|â–‹         | 2/30 [00:09<02:01,  4.33s/it]Training:   7%|â–‹         | 2/30 [00:09<02:01,  4.33s/it]Training:  10%|â–ˆ         | 3/30 [00:16<02:21,  5.25s/it]Training:  10%|â–ˆ         | 3/30 [00:16<02:21,  5.25s/it]Training:  10%|â–ˆ         | 3/30 [00:16<02:21,  5.25s/it]Training:  10%|â–ˆ         | 3/30 [00:16<02:21,  5.25s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:22<02:26,  5.65s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:22<02:26,  5.65s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:22<02:26,  5.65s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:22<02:26,  5.65s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:29<02:30,  6.02s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:29<02:30,  6.02s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:29<02:30,  6.02s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:29<02:30,  6.02s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:29<01:42,  4.25s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:29<01:42,  4.25s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:29<01:42,  4.26s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:29<01:42,  4.25s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:30<01:12,  3.16s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:30<01:12,  3.16s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:30<01:12,  3.16s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:30<01:12,  3.16s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:31<00:53,  2.44s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:31<00:53,  2.44s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:31<00:53,  2.44s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:31<00:53,  2.44s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:32<00:39,  1.90s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:32<00:39,  1.90s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:32<00:39,  1.90s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:32<00:39,  1.90s/it]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:33<00:31,  1.57s/it]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:33<00:31,  1.57s/it]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:33<00:31,  1.57s/it]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:33<00:31,  1.57s/it]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:34<00:27,  1.43s/it]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:34<00:27,  1.43s/it]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:34<00:27,  1.43s/it]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:34<00:27,  1.43s/it]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:35<00:22,  1.26s/it]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:35<00:22,  1.26s/it]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:35<00:22,  1.26s/it]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:35<00:22,  1.26s/it]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:36<00:19,  1.16s/it]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:36<00:19,  1.16s/it]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:36<00:19,  1.16s/it]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:36<00:19,  1.16s/it]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:36<00:16,  1.04s/it]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:36<00:16,  1.04s/it]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:36<00:16,  1.04s/it]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:36<00:16,  1.04s/it]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:38<00:16,  1.10s/it]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:38<00:16,  1.10s/it]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:38<00:16,  1.10s/it]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:38<00:16,  1.10s/it]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:39<00:14,  1.02s/it]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:39<00:14,  1.02s/it]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:39<00:14,  1.02s/it]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:39<00:14,  1.02s/it]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:39<00:12,  1.07it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:39<00:12,  1.07it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:39<00:12,  1.07it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:39<00:12,  1.07it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:40<00:10,  1.13it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:40<00:10,  1.13it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:40<00:10,  1.13it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:40<00:10,  1.12it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:41<00:09,  1.17it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:41<00:09,  1.17it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:41<00:09,  1.17it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:41<00:09,  1.17it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:42<00:08,  1.15it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:42<00:08,  1.15it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:42<00:08,  1.15it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:42<00:08,  1.15it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:43<00:07,  1.18it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:43<00:07,  1.18it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:43<00:07,  1.18it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:43<00:07,  1.18it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:43<00:06,  1.24it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:43<00:06,  1.24it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:43<00:06,  1.24it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:43<00:06,  1.24it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:44<00:05,  1.21it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:44<00:05,  1.21it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:44<00:05,  1.21it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:44<00:05,  1.21it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:45<00:04,  1.26it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:45<00:04,  1.26it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:45<00:04,  1.26it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:45<00:04,  1.26it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:46<00:04,  1.17it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:46<00:04,  1.17it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:46<00:04,  1.17it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:46<00:04,  1.17it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:47<00:03,  1.19it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:47<00:03,  1.19it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:47<00:03,  1.19it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:47<00:03,  1.19it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:47<00:02,  1.19it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:47<00:02,  1.19it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:47<00:02,  1.19it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:47<00:02,  1.19it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:48<00:01,  1.21it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:48<00:01,  1.21it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:48<00:01,  1.21it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:48<00:01,  1.21it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:49<00:00,  1.26it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:49<00:00,  1.26it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:49<00:00,  1.26it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:49<00:00,  1.26it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:50<00:00,  1.25it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:50<00:00,  1.25it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:50<00:00,  1.25it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:50<00:00,  1.25it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:51<00:00,  1.71s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:51<00:00,  1.71s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:51<00:00,  1.71s/it]
  Batch 0: Grad norm = 0.625624
  Batch 10: Grad norm = 0.530319
  Batch 20: Grad norm = 0.304897

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:51<00:00,  1.71s/it]
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.625624
  Batch 10: Grad norm = 0.530319
  Batch 20: Grad norm = 0.304897
  Batch 0: Grad norm = 0.625624
  Batch 10: Grad norm = 0.530319
  Batch 20: Grad norm = 0.304897
Train Loss: 1.696887, Cosine Sim: 0.0924

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9900, log_space=4.5951, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9900)!
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.625624
  Batch 10: Grad norm = 0.530319
  Batch 20: Grad norm = 0.304897
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.03s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.05s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.05s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.07s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:10<00:10,  5.43s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:10<00:10,  5.43s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:10<00:10,  5.43s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:10<00:10,  5.43s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:16<00:05,  5.58s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:16<00:05,  5.58s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:16<00:05,  5.59s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:16<00:05,  5.60s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:16<00:00,  3.43s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:16<00:00,  3.43s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:16<00:00,  3.44s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:16<00:00,  3.44s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:17<00:00,  4.43s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:17<00:00,  4.42s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:17<00:00,  4.43s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:17<00:00,  4.44s/it]

Val Loss: 1.987429, Cosine Sim: 0.0537, MSE: 1.9874
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 2/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:48,  5.83s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:48,  5.83s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:48,  5.83s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:49,  5.83s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.82s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.82s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.82s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.82s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.94s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.94s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.94s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.94s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.48s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.48s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.48s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.48s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.31s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.31s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.31s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.31s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.16s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.16s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.16s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.16s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:24,  1.08s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:24,  1.08s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:24,  1.08s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:24,  1.08s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.00it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.00it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.00it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.00it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.10it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.10it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.10it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.10it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.13it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.13it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.13it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.13it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:16,  1.16it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:16,  1.16it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:16,  1.16it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:16,  1.16it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.20it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.20it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.20it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.20it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.19it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.18it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.18it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.18it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.19it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.19it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.19it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.19it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.09it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.09it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.09it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.09it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.15it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:10,  1.19it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:10,  1.19it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:10,  1.19it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:10,  1.19it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.18it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.18it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.18it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.18it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.19it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.19it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.19it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.19it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.23it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.23it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.23it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.23it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.20it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.20it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.20it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.20it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.23it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.23it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.23it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.23it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.25it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.25it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.25it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.25it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:24<00:04,  1.25it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:24<00:04,  1.25it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:24<00:04,  1.25it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:24<00:04,  1.25it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:25<00:04,  1.20it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:25<00:04,  1.20it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:25<00:04,  1.20it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:25<00:04,  1.20it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:26<00:03,  1.20it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:26<00:03,  1.20it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:26<00:03,  1.20it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:26<00:03,  1.20it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.21it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.21it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.21it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.21it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.23it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.23it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.23it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.23it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.25it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.25it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.25it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.25it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.14it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.14it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.14it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.14it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]
  Batch 0: Grad norm = 0.239375
  Batch 10: Grad norm = 0.381055
  Batch 20: Grad norm = 0.313026
Train Loss: 1.644974, Cosine Sim: 0.1609

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9900, log_space=4.5944, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9900)!
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]  Batch 0: Grad norm = 0.239375
  Batch 10: Grad norm = 0.381055
  Batch 20: Grad norm = 0.313026

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.239375
  Batch 10: Grad norm = 0.381055
  Batch 20: Grad norm = 0.313026
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.239375
  Batch 10: Grad norm = 0.381055
  Batch 20: Grad norm = 0.313026
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  4.93s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  5.00s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.03s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.11s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.04s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.15s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.15s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.21s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.17s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.28it/s]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.27it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.59s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.61s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.64s/it]
Val Loss: 1.953870, Cosine Sim: 0.0733, MSE: 1.9539
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 3/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:45,  5.72s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:45,  5.72s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:45,  5.72s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:45,  5.72s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.78s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.78s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.78s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.78s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.91s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.91s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.91s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.91s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.46s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.46s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.46s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.46s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.13s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.13s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.13s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.13s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.04s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.04s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.04s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.04s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.01s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.01s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.01s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.01s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:20,  1.05it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:20,  1.05it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:20,  1.05it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:20,  1.05it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.09it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.09it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.09it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.09it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:15,  1.15it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:15,  1.15it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:15,  1.15it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:15,  1.15it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.17it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.17it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.17it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.17it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:12,  1.25it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:12,  1.25it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:12,  1.25it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:12,  1.25it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.19it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.19it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.19it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.19it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.12it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.11it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.11it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.11it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.11it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.13it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.13it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.13it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.13it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.15it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.15it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.15it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.15it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.12it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.12it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.12it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.12it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.13it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.13it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.13it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.13it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.15it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.15it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.15it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.13it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.13it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.13it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.13it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.14it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.14it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.14it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.14it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.10it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.10it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.10it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.10it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.13it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.13it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.13it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.13it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.17it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.17it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.17it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.17it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.25it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.25it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.25it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.25it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.22it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.22it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.22it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.22it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]
  Batch 0: Grad norm = 0.231707
  Batch 10: Grad norm = 0.148002
  Batch 20: Grad norm = 0.286663

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
  Batch 0: Grad norm = 0.231707
  Batch 10: Grad norm = 0.148002
  Batch 20: Grad norm = 0.286663
  Batch 0: Grad norm = 0.231707
  Batch 10: Grad norm = 0.148002
  Batch 20: Grad norm = 0.286663
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.231707
  Batch 10: Grad norm = 0.148002
  Batch 20: Grad norm = 0.286663
Train Loss: 1.583778, Cosine Sim: 0.2071

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9900, log_space=4.5944, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9900)!
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.06s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.15s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.21s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.21s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.21s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.23s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.22s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.26s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.28s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.28s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.24it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.22it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.22it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.65s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.67s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.68s/it]
Val Loss: 1.934082, Cosine Sim: 0.0762, MSE: 1.9341
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 4/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:48,  5.81s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:48,  5.81s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:48,  5.81s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:48,  5.81s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.89s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.89s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.89s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.89s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:37,  1.45s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:37,  1.45s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:37,  1.45s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:37,  1.45s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.21s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.21s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.21s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.21s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.15s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.15s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.15s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.15s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.01s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.01s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.01s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.01s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.11it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.11it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.11it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.11it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.09it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.09it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.09it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.09it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.08it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.08it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.08it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.08it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.16it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.16it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.16it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.16it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.20it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.20it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.20it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.20it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:12,  1.23it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:12,  1.23it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:12,  1.23it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:12,  1.23it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.16it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.16it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.16it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.16it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.16it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.16it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.16it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.16it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.15it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.15it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.15it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.15it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.22it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.22it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.22it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.22it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.18it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.18it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.18it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.18it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.15it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.15it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.15it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.15it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.16it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.15it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.15it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.15it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.15it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.12it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.12it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.12it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.12it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.08it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.08it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.08it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.08it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.09it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.09it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.09it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.09it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.11it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.11it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.11it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.11it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.14it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.14it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.14it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.14it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.08it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.08it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.08it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.08it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]  Batch 0: Grad norm = 0.269088
  Batch 10: Grad norm = 0.157657
  Batch 20: Grad norm = 0.323756

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.269088
  Batch 10: Grad norm = 0.157657
  Batch 20: Grad norm = 0.323756
  Batch 0: Grad norm = 0.269088
  Batch 10: Grad norm = 0.157657
  Batch 20: Grad norm = 0.323756
Train Loss: 1.574226, Cosine Sim: 0.1884

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9900, log_space=4.5938, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9900)!
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.269088
  Batch 10: Grad norm = 0.157657
  Batch 20: Grad norm = 0.323756
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  4.99s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  5.00s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.01s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.04s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.14s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.15s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.14s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]

Val Loss: 1.908562, Cosine Sim: 0.0748, MSE: 1.9086
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 5/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:46,  5.75s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:46,  5.75s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:46,  5.75s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:46,  5.75s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.81s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.81s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.81s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.81s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.92s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.92s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.92s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.93s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.53s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.53s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.53s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.53s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:33,  1.33s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:33,  1.33s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:33,  1.33s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:33,  1.33s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:30,  1.27s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:30,  1.27s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:30,  1.27s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:30,  1.27s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:25,  1.10s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:25,  1.10s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:25,  1.10s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:25,  1.10s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:12<00:22,  1.04s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:12<00:22,  1.04s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:12<00:22,  1.04s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:12<00:22,  1.04s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:13<00:21,  1.02s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:13<00:21,  1.02s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:13<00:21,  1.02s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:13<00:21,  1.02s/it]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:14<00:20,  1.03s/it]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:14<00:20,  1.03s/it]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:14<00:20,  1.03s/it]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:14<00:20,  1.03s/it]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:18,  1.03it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:18,  1.03it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:18,  1.03it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:18,  1.03it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.07it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.07it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.07it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.07it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.12it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.12it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.12it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.12it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:13,  1.17it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:13,  1.17it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:13,  1.17it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:13,  1.17it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.15it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.15it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.15it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:19<00:12,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:19<00:12,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:19<00:12,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:19<00:12,  1.12it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:10,  1.19it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:10,  1.19it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:10,  1.19it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:10,  1.19it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:09,  1.25it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:09,  1.25it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:09,  1.25it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:09,  1.25it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:08,  1.29it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:08,  1.29it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:08,  1.29it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:08,  1.29it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:07,  1.28it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:07,  1.27it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:07,  1.27it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:07,  1.27it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:07,  1.22it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:07,  1.22it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:07,  1.22it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:07,  1.22it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:06,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:06,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:06,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:06,  1.16it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.14it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.14it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.14it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.14it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.20it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.20it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.20it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.20it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.19it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.19it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.19it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.19it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.21it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.21it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.21it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.21it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.23it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.23it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.23it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.23it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.18it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.18it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.18it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.18it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.21it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.21it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.21it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.21it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.19it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.19it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.19it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.19it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]  Batch 0: Grad norm = 0.330217
  Batch 10: Grad norm = 0.304917
  Batch 20: Grad norm = 0.229602
Train Loss: 1.533626, Cosine Sim: 0.1951

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9900, log_space=4.5933, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9900)!

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.330217
  Batch 10: Grad norm = 0.304917
  Batch 20: Grad norm = 0.229602
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.330217
  Batch 10: Grad norm = 0.304917
  Batch 20: Grad norm = 0.229602
  Batch 0: Grad norm = 0.330217
  Batch 10: Grad norm = 0.304917
  Batch 20: Grad norm = 0.229602
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.10s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.12s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.14s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.13s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.18s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.20s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.20s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.20s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.26s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.27s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.27s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.24it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.24it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.23it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.22it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.64s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.65s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.65s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.66s/it]
Val Loss: 1.889916, Cosine Sim: 0.0739, MSE: 1.8899
Learning Rate: 2.00e-04
Saved checkpoint to models/ablation_non_multi_hop/checkpoint_epoch_5.pt
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 6/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]