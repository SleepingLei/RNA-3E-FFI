nohup: ignoring input
==========================================
Training with Memory Optimization
==========================================
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(

Starting distributed training with 4 GPUs...
Spawning processes...

/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
[rank1]:[W1111 22:58:27.543412879 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank2]:[W1111 22:58:27.560634836 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank3]:[W1111 22:58:27.996118664 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank0]:[W1111 22:58:27.016959019 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
/personal/RNA-3E-FFI/scripts/04_train_model.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(graph_path)
/personal/RNA-3E-FFI/scripts/04_train_model.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(graph_path)
/personal/RNA-3E-FFI/scripts/04_train_model.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(graph_path)
/personal/RNA-3E-FFI/scripts/04_train_model.py:138: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  data = torch.load(graph_path)
/opt/mamba/envs/RNA/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/mamba/envs/RNA/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
/opt/mamba/envs/RNA/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Dataset initialized with 954 valid complexes
Dataset initialized with 117 valid complexes
Using pooling type: multihead_attention
/opt/mamba/envs/RNA/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Training:   0%|          | 0/30 [00:00<?, ?it/s]Dataset initialized with 954 valid complexes
Dataset initialized with 117 valid complexes
Using pooling type: multihead_attention
Dataset initialized with 954 valid complexes
Dataset initialized with 117 valid complexes
Using pooling type: multihead_attention
Using device: cuda:0
Distributed training with 4 GPUs
Loading splits from data/splits/filtered_splits.json
Dataset splits: Train=954, Val=117, Test=122
Dataset initialized with 954 valid complexes
Dataset initialized with 117 valid complexes

Initializing v3.0 model (with V3 improvements)...
Using RNAPocketEncoderV3 (geometric MP + enhanced invariants)
  Geometric MP: True
  Enhanced invariants: True (204-dim vs 56-dim)
  Improved layers: True (Bessel+Cutoff+ImprovedMP)
  Norm type: layer
  Attention heads: 8
  Initial angle weight: 0.500
  Initial dihedral weight: 0.500
  Initial nonbonded weight: 1.000
Using pooling type: multihead_attention
Model has 3,183,661 parameters

Model configuration:
  Multi-hop: False
  Non-bonded: True
  Pooling: attention
  Initial nonbonded weight: 0.990

Starting training from scratch...


============================================================
Training Configuration
============================================================
Batch Size per GPU: 8
Number of GPUs: 4
Effective Batch Size: 32

Mixed Precision Training (AMP): Disabled

Loss Function: mse

Gradient Clipping: 2.0 (manual)
Gradient Monitoring: ENABLED (will print every 50 batches)
============================================================

Starting training...

Epoch 1/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:08<03:58,  8.24s/it]Training:   3%|â–Ž         | 1/30 [00:08<03:58,  8.24s/it]Training:   3%|â–Ž         | 1/30 [00:08<03:58,  8.24s/it]Training:   3%|â–Ž         | 1/30 [00:08<03:59,  8.26s/it]Training:   7%|â–‹         | 2/30 [00:09<02:01,  4.35s/it]Training:   7%|â–‹         | 2/30 [00:09<02:01,  4.35s/it]Training:   7%|â–‹         | 2/30 [00:09<02:01,  4.35s/it]Training:   7%|â–‹         | 2/30 [00:09<02:01,  4.35s/it]Training:  10%|â–ˆ         | 3/30 [00:16<02:22,  5.26s/it]Training:  10%|â–ˆ         | 3/30 [00:16<02:22,  5.26s/it]Training:  10%|â–ˆ         | 3/30 [00:16<02:22,  5.26s/it]Training:  10%|â–ˆ         | 3/30 [00:16<02:22,  5.26s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:22<02:26,  5.65s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:22<02:26,  5.65s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:22<02:26,  5.65s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:22<02:26,  5.65s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:29<02:30,  6.02s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:29<02:30,  6.02s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:29<02:30,  6.03s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:29<02:30,  6.03s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:29<01:42,  4.26s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:29<01:42,  4.26s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:29<01:42,  4.26s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:29<01:42,  4.26s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:30<01:12,  3.17s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:30<01:12,  3.17s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:30<01:12,  3.17s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:30<01:12,  3.17s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:31<00:53,  2.44s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:31<00:53,  2.44s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:31<00:53,  2.44s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:31<00:53,  2.44s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:32<00:39,  1.90s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:32<00:39,  1.90s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:32<00:39,  1.90s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:32<00:39,  1.90s/it]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:33<00:31,  1.57s/it]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:33<00:31,  1.57s/it]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:33<00:31,  1.57s/it]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:33<00:31,  1.57s/it]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:34<00:27,  1.43s/it]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:34<00:27,  1.43s/it]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:34<00:27,  1.43s/it]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:34<00:27,  1.43s/it]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:35<00:22,  1.23s/it]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:35<00:22,  1.23s/it]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:35<00:22,  1.23s/it]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:35<00:22,  1.23s/it]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:36<00:19,  1.13s/it]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:36<00:19,  1.13s/it]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:36<00:19,  1.13s/it]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:36<00:19,  1.14s/it]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:36<00:16,  1.02s/it]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:36<00:16,  1.02s/it]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:36<00:16,  1.02s/it]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:36<00:16,  1.02s/it]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:38<00:16,  1.09s/it]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:38<00:16,  1.09s/it]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:38<00:16,  1.09s/it]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:38<00:16,  1.09s/it]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:38<00:14,  1.01s/it]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:38<00:14,  1.01s/it]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:38<00:14,  1.01s/it]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:38<00:14,  1.01s/it]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:39<00:12,  1.08it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:39<00:12,  1.08it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:39<00:12,  1.08it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:39<00:12,  1.08it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:40<00:10,  1.13it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:40<00:10,  1.13it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:40<00:10,  1.13it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:40<00:10,  1.13it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:41<00:09,  1.17it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:41<00:09,  1.17it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:41<00:09,  1.17it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:41<00:09,  1.17it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:42<00:08,  1.15it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:42<00:08,  1.15it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:42<00:08,  1.15it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:42<00:08,  1.15it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:42<00:07,  1.18it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:42<00:07,  1.19it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:42<00:07,  1.18it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:42<00:07,  1.19it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:43<00:06,  1.25it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:43<00:06,  1.25it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:43<00:06,  1.25it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:43<00:06,  1.25it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:44<00:05,  1.22it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:44<00:05,  1.21it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:44<00:05,  1.21it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:44<00:05,  1.21it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:45<00:04,  1.26it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:45<00:04,  1.26it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:45<00:04,  1.26it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:45<00:04,  1.26it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:46<00:04,  1.17it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:46<00:04,  1.17it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:46<00:04,  1.17it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:46<00:04,  1.17it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:47<00:03,  1.19it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:47<00:03,  1.19it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:47<00:03,  1.19it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:47<00:03,  1.19it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:47<00:02,  1.19it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:47<00:02,  1.19it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:47<00:02,  1.19it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:47<00:02,  1.19it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:48<00:01,  1.22it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:48<00:01,  1.22it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:48<00:01,  1.22it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:48<00:01,  1.22it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:49<00:00,  1.26it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:49<00:00,  1.26it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:49<00:00,  1.26it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:49<00:00,  1.26it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:50<00:00,  1.25it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:50<00:00,  1.25it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:50<00:00,  1.25it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:50<00:00,  1.24it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:51<00:00,  1.71s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:51<00:00,  1.71s/it]  Batch 0: Grad norm = 0.625624
  Batch 10: Grad norm = 0.530319
  Batch 20: Grad norm = 0.304897
Train Loss: 1.696887, Cosine Sim: 0.0924

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9900, log_space=4.5951, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9900)!
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:51<00:00,  1.71s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.625624
  Batch 10: Grad norm = 0.530319
  Batch 20: Grad norm = 0.304897
  Batch 0: Grad norm = 0.625624
  Batch 10: Grad norm = 0.530319
  Batch 20: Grad norm = 0.304897
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:51<00:00,  1.71s/it]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.625624
  Batch 10: Grad norm = 0.530319
  Batch 20: Grad norm = 0.304897
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  5.00s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.02s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.12s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.11s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:10<00:10,  5.43s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:10<00:10,  5.42s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:10<00:10,  5.49s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:10<00:10,  5.48s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:16<00:05,  5.63s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:16<00:05,  5.63s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:16<00:05,  5.63s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:16<00:05,  5.64s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:16<00:00,  3.46s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:16<00:00,  3.46s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:16<00:00,  3.46s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:16<00:00,  3.46s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:17<00:00,  4.44s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:17<00:00,  4.45s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:17<00:00,  4.45s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:17<00:00,  4.46s/it]
Val Loss: 1.987429, Cosine Sim: 0.0537, MSE: 1.9874
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 2/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:47,  5.78s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:47,  5.78s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:47,  5.78s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:47,  5.78s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.80s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.80s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.80s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.80s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.47s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.47s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.47s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.47s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.31s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.31s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.31s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.31s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.16s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.16s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.16s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.16s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.08s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.08s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.08s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.08s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.10it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.10it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.10it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.10it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.13it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.13it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.13it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.13it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:16,  1.16it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:16,  1.16it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:16,  1.16it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:16,  1.16it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.19it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.19it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.19it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.19it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.16it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.16it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.16it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.16it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.17it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.17it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.17it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.17it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.08it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.07it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.07it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.07it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:10,  1.18it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:10,  1.18it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:10,  1.18it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:10,  1.18it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.18it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.18it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.18it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.18it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.19it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.19it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.19it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.19it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.23it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.23it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.23it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.23it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.21it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.21it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.21it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.21it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.23it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.23it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.23it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.23it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.25it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.25it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.25it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.25it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:24<00:04,  1.24it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:24<00:04,  1.24it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:24<00:04,  1.24it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:24<00:04,  1.24it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:25<00:04,  1.20it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:25<00:04,  1.20it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:25<00:04,  1.20it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:25<00:04,  1.20it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:26<00:03,  1.20it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:26<00:03,  1.20it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:26<00:03,  1.20it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:26<00:03,  1.20it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.21it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.21it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.21it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.21it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.23it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.23it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.23it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.23it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.25it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.25it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.25it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.25it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]
  Batch 0: Grad norm = 0.239375
  Batch 10: Grad norm = 0.381057
  Batch 20: Grad norm = 0.313025

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.239375
  Batch 10: Grad norm = 0.381057
  Batch 20: Grad norm = 0.313025
  Batch 0: Grad norm = 0.239375
  Batch 10: Grad norm = 0.381057
  Batch 20: Grad norm = 0.313025
  Batch 0: Grad norm = 0.239375
  Batch 10: Grad norm = 0.381057
  Batch 20: Grad norm = 0.313025
Train Loss: 1.644974, Cosine Sim: 0.1609

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9900, log_space=4.5944, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9900)!
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  5.00s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  5.00s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.01s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.01s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.15s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.14s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.14s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.15s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.27it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.61s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]

Val Loss: 1.953874, Cosine Sim: 0.0733, MSE: 1.9539
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 3/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:45,  5.70s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:45,  5.70s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:45,  5.70s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:45,  5.70s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.78s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.78s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.78s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.78s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.91s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.91s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.91s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.91s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.46s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.46s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.46s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.46s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.30s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.13s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.13s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.13s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.13s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.04s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.04s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.04s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.04s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.02s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.02s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.02s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.02s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:20,  1.05it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:20,  1.05it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:20,  1.05it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:20,  1.04it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.09it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.09it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.09it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.09it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:15,  1.15it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:15,  1.15it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:15,  1.15it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:15,  1.15it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.18it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.18it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.18it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.18it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:12,  1.25it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:12,  1.25it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:12,  1.25it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:12,  1.25it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.19it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.19it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.19it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.19it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.12it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.11it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.11it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.11it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.11it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.13it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.13it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.13it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.13it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.14it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.14it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.14it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.14it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.12it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.12it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.12it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.12it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.13it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.14it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.13it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.13it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.14it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.14it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.14it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.14it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.14it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.14it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.14it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.14it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.14it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.14it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.14it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.14it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.10it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.10it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.10it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.10it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.13it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.13it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.13it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.13it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.16it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.16it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.16it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.16it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.24it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.24it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.23it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.23it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.21it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.21it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.21it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.21it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]
  Batch 0: Grad norm = 0.231607
  Batch 10: Grad norm = 0.147940
  Batch 20: Grad norm = 0.286694

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.231607
  Batch 10: Grad norm = 0.147940
  Batch 20: Grad norm = 0.286694
  Batch 0: Grad norm = 0.231607
  Batch 10: Grad norm = 0.147940
  Batch 20: Grad norm = 0.286694
Train Loss: 1.583777, Cosine Sim: 0.2071

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9900, log_space=4.5943, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9900)!
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.231607
  Batch 10: Grad norm = 0.147940
  Batch 20: Grad norm = 0.286694
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  4.99s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.12s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.14s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.22s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.25s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.20s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.23s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.24s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.28s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.29s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.24it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.22it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.21it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.60s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.64s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.67s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.67s/it]
Val Loss: 1.934032, Cosine Sim: 0.0762, MSE: 1.9340
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 4/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:48,  5.81s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:48,  5.81s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:48,  5.81s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:48,  5.81s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.89s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.89s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.89s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.89s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.94s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.94s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.94s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.94s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.46s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.46s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.46s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.46s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.21s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.21s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.22s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.22s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:28,  1.17s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:28,  1.17s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:28,  1.17s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:28,  1.17s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.02s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.02s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.02s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.02s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.00it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.00it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.00it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.00it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.10it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.10it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.10it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.10it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.08it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.08it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.08it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.08it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.07it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.07it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.07it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.07it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:15,  1.16it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:15,  1.16it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:15,  1.16it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:15,  1.16it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.19it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.19it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.19it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.19it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:12,  1.23it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.23it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.23it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.23it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.16it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.16it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.16it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.16it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.16it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.16it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.16it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.16it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.16it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.16it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.16it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.16it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:08,  1.22it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:08,  1.22it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:08,  1.22it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:08,  1.22it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.18it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.18it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.18it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.18it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.15it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.15it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.15it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.15it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.16it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.16it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.16it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.16it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.16it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.12it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.12it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.12it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.12it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.08it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.08it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.08it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.08it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.09it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.09it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.09it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.09it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.10it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.10it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.10it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.10it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.14it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.14it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.14it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.14it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.08it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.08it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.08it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.07it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.07s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.07s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.07s/it]
  Batch 0: Grad norm = 0.269355
  Batch 10: Grad norm = 0.157573
  Batch 20: Grad norm = 0.324337
Train Loss: 1.574224, Cosine Sim: 0.1884

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9900, log_space=4.5937, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9900)!

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.07s/it]
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.269355
  Batch 10: Grad norm = 0.157573
  Batch 20: Grad norm = 0.324337
  Batch 0: Grad norm = 0.269355
  Batch 10: Grad norm = 0.157573
  Batch 20: Grad norm = 0.324337
  Batch 0: Grad norm = 0.269355
  Batch 10: Grad norm = 0.157573
  Batch 20: Grad norm = 0.324337
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.00s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.03s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.03s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.04s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.15s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.15s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.15s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]

Val Loss: 1.908554, Cosine Sim: 0.0748, MSE: 1.9086
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 5/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:47,  5.79s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:47,  5.79s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:47,  5.79s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:47,  5.79s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.82s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.82s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.82s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.82s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:40,  1.54s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:40,  1.54s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:40,  1.54s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:40,  1.54s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:33,  1.33s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:33,  1.33s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:33,  1.33s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:33,  1.33s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:30,  1.27s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:30,  1.27s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:30,  1.27s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:30,  1.27s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:25,  1.10s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:25,  1.10s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:25,  1.10s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:25,  1.10s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:12<00:22,  1.04s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:12<00:22,  1.04s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:12<00:22,  1.04s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:12<00:22,  1.04s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:13<00:21,  1.02s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:13<00:21,  1.02s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:13<00:21,  1.02s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:13<00:21,  1.02s/it]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:14<00:20,  1.03s/it]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:14<00:20,  1.03s/it]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:14<00:20,  1.03s/it]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:14<00:20,  1.03s/it]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:18,  1.03it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:18,  1.03it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:18,  1.03it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:18,  1.03it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.07it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.07it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.07it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.07it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.12it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.12it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.12it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.12it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:13,  1.17it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:13,  1.17it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:13,  1.17it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:13,  1.17it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.15it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.15it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.15it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:19<00:12,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:19<00:12,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:19<00:12,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:19<00:12,  1.12it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:10,  1.19it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:10,  1.19it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:10,  1.19it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:10,  1.19it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:09,  1.25it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:09,  1.25it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:09,  1.25it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:09,  1.25it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:08,  1.30it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:08,  1.30it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:08,  1.30it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:08,  1.30it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:07,  1.28it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:07,  1.28it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:07,  1.28it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:07,  1.28it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:07,  1.22it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:07,  1.22it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:07,  1.22it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:07,  1.22it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:06,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:06,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:06,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:06,  1.16it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.15it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.21it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.21it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.21it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.21it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.19it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.19it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.19it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.19it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.21it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.21it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.21it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.21it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.23it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.23it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.23it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.23it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.18it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.18it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.18it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.18it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.21it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.21it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.21it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.21it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.19it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.19it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.19it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.19it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]
  Batch 0: Grad norm = 0.330798
  Batch 10: Grad norm = 0.305081
  Batch 20: Grad norm = 0.229498
Train Loss: 1.533615, Cosine Sim: 0.1951

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9900, log_space=4.5933, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9900)!

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.330798
  Batch 10: Grad norm = 0.305081
  Batch 20: Grad norm = 0.229498
  Batch 0: Grad norm = 0.330798
  Batch 10: Grad norm = 0.305081
  Batch 20: Grad norm = 0.229498
  Batch 0: Grad norm = 0.330798
  Batch 10: Grad norm = 0.305081
  Batch 20: Grad norm = 0.229498
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.03s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.05s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.07s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.06s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.17s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.24it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.24it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.64s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]
Val Loss: 1.889880, Cosine Sim: 0.0739, MSE: 1.8899
Learning Rate: 2.00e-04
Saved checkpoint to models/ablation_non_multi_hop/checkpoint_epoch_5.pt
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 6/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:44,  5.66s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:44,  5.66s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:44,  5.66s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:44,  5.66s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.85s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.85s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.85s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.85s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:37,  1.45s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:37,  1.45s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:37,  1.45s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:37,  1.45s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.22s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.22s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.22s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.22s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.14s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.14s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.14s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.14s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.05s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.05s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.05s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.05s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:20,  1.03it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:20,  1.03it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:20,  1.03it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:20,  1.03it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.08it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.08it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.08it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.08it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.07it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.07it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.07it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.07it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.08it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.08it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.08it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.08it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.13it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.13it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.13it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.13it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:14,  1.10it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:14,  1.10it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:14,  1.10it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:14,  1.10it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.08it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.08it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.08it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.08it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:13,  1.06it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:13,  1.06it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:13,  1.06it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:13,  1.07it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.14it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.14it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.14it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.14it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.14it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.14it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.14it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.14it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.18it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.18it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.18it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.18it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.17it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.17it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.17it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.17it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.20it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.20it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.20it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.20it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.25it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.25it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.25it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.25it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.23it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.23it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.23it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.23it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.22it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.22it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.22it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.22it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.16it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.16it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.16it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.15it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.11it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.11it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.11it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.11it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.11it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.11it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.11it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.11it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.15it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.15it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.15it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.15it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.15it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.15it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.15it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.16it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.16it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.16it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.16it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]  Batch 0: Grad norm = 0.229888
  Batch 10: Grad norm = 0.228489
  Batch 20: Grad norm = 0.139175
Train Loss: 1.553295, Cosine Sim: 0.1861

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9900, log_space=4.5925, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9900)!

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.229888
  Batch 10: Grad norm = 0.228489
  Batch 20: Grad norm = 0.139175
  Batch 0: Grad norm = 0.229888
  Batch 10: Grad norm = 0.228489
  Batch 20: Grad norm = 0.139175
  Batch 0: Grad norm = 0.229888
  Batch 10: Grad norm = 0.228489
  Batch 20: Grad norm = 0.139175
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.01s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.09s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.09s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.10s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.14s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.18s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.18s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.18s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.26s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.26s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.24it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.24it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.61s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.64s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.65s/it]
Val Loss: 1.870501, Cosine Sim: 0.0745, MSE: 1.8705
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 7/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:42,  5.60s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:42,  5.60s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:42,  5.60s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:42,  5.60s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.83s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.83s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.83s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.83s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.91s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.91s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.91s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.91s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:37,  1.45s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:37,  1.45s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:37,  1.45s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:37,  1.45s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.20s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.20s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.20s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.20s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:26,  1.11s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:26,  1.11s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:26,  1.11s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:26,  1.11s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.01s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.01s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.01s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.01s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.08it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.08it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.08it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.08it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.15it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.15it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.15it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.15it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:12<00:17,  1.13it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:12<00:17,  1.12it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:12<00:17,  1.12it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:12<00:17,  1.12it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:13<00:16,  1.17it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:13<00:16,  1.17it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:13<00:16,  1.17it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:13<00:16,  1.17it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.16it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.16it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.16it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.16it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.15it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.15it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.15it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.15it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:14,  1.14it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:14,  1.14it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:14,  1.14it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:14,  1.14it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:14,  1.05it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:14,  1.05it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:14,  1.05it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:14,  1.05it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.09it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.09it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.09it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.09it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.12it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.12it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.12it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.12it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.12it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.12it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.12it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.12it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.12it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.12it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.12it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.12it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:09,  1.10it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:09,  1.10it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:09,  1.10it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:09,  1.10it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:08,  1.11it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:08,  1.11it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:08,  1.11it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:08,  1.11it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.20it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.20it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.20it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.20it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.17it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.17it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.17it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.17it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.13it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.13it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.13it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.13it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.15it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.15it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.15it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.15it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.13it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.13it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.13it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.13it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.12it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.12it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.12it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.12it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.18it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.18it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.18it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.18it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.15it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.15it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.15it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.20it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.20it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.20it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.20it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]

  Batch 0: Grad norm = 0.169274
  Batch 10: Grad norm = 0.355063
  Batch 20: Grad norm = 0.123591
  Batch 0: Grad norm = 0.169274
  Batch 10: Grad norm = 0.355063
  Batch 20: Grad norm = 0.123591
  Batch 0: Grad norm = 0.169274
  Batch 10: Grad norm = 0.355063
  Batch 20: Grad norm = 0.123591
Train Loss: 1.462599, Cosine Sim: 0.1989

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9900, log_space=4.5920, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9900)!
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.169274
  Batch 10: Grad norm = 0.355063
  Batch 20: Grad norm = 0.123591
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.04s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.04s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.06s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.10s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.19s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.26s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.24it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.64s/it]
Val Loss: 1.845455, Cosine Sim: 0.0770, MSE: 1.8455
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 8/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:43,  5.64s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:43,  5.64s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:43,  5.64s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:43,  5.64s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.82s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.82s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.82s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.82s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.48s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.48s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.48s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.48s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:31,  1.25s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:31,  1.25s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:31,  1.25s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:31,  1.25s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.13s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.13s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.13s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.13s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.05s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.05s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.05s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.05s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.05it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.05it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.05it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.05it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.13it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.13it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.13it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.13it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.12it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.11it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.11it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.11it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.08it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.08it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.08it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.08it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:15,  1.12it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:15,  1.12it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:15,  1.12it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:15,  1.12it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:14,  1.09it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:14,  1.09it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:14,  1.09it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:14,  1.09it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.12it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.12it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.12it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.15it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.10it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.10it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.10it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.10it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.17it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.17it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.17it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.17it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.22it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.22it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.22it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.22it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.16it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.16it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.16it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.16it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.15it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.15it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.15it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.15it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.18it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.18it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.18it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.18it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.19it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.19it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.19it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.19it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.14it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.14it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.14it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.14it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.12it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.12it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.12it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.12it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.11it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.11it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.11it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.11it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.14it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.14it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.14it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.14it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.16it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.16it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.16it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.16it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.17it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.17it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.17it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.17it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]
  Batch 0: Grad norm = 0.362824
  Batch 10: Grad norm = 0.208309
  Batch 20: Grad norm = 0.341756

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.362824
  Batch 10: Grad norm = 0.208309
  Batch 20: Grad norm = 0.341756
Train Loss: 1.538967, Cosine Sim: 0.1794

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9900, log_space=4.5912, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9900)!
  Batch 0: Grad norm = 0.362824
  Batch 10: Grad norm = 0.208309
  Batch 20: Grad norm = 0.341756
  Batch 0: Grad norm = 0.362824
  Batch 10: Grad norm = 0.208309
  Batch 20: Grad norm = 0.341756
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.01s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.04s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.04s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.06s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.15s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.64s/it]
Val Loss: 1.821689, Cosine Sim: 0.0801, MSE: 1.8217
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 9/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:42,  5.59s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:42,  5.59s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:42,  5.59s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:42,  5.59s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.76s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.76s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.76s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.76s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:50,  1.88s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:50,  1.88s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:50,  1.88s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:50,  1.89s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:07<00:37,  1.44s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:07<00:37,  1.44s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:07<00:37,  1.44s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:07<00:37,  1.44s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:31,  1.27s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:31,  1.27s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:31,  1.27s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:31,  1.27s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.14s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.15s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.15s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.15s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:22,  1.00it/s]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:22,  1.00it/s]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:22,  1.00it/s]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:22,  1.00it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.09it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.09it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.09it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.09it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:11<00:17,  1.18it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:11<00:17,  1.18it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:11<00:17,  1.18it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:11<00:17,  1.18it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:12<00:16,  1.19it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:12<00:16,  1.19it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:12<00:16,  1.19it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:12<00:16,  1.19it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:13<00:16,  1.15it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:13<00:16,  1.15it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:13<00:16,  1.15it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:13<00:16,  1.15it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:14,  1.22it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:14,  1.22it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:14,  1.22it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:14,  1.22it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.19it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.19it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.19it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.19it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.15it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.15it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.15it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.15it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.18it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.18it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.18it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.18it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:17<00:12,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:17<00:12,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:17<00:12,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:17<00:12,  1.15it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:18<00:10,  1.20it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:18<00:10,  1.20it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:18<00:10,  1.20it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:18<00:10,  1.20it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:19<00:09,  1.23it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:19<00:09,  1.23it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:19<00:09,  1.23it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:19<00:09,  1.23it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.20it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.20it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.20it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.20it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:09,  1.09it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:09,  1.09it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:09,  1.09it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:09,  1.09it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:08,  1.09it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:08,  1.09it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:08,  1.09it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:08,  1.09it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:07,  1.09it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:07,  1.09it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:07,  1.09it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:07,  1.09it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.14it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.14it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.14it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.14it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:24<00:05,  1.16it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:24<00:05,  1.16it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:24<00:05,  1.15it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:24<00:05,  1.15it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:25<00:04,  1.17it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:25<00:04,  1.17it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:25<00:04,  1.17it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:25<00:04,  1.16it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:26<00:03,  1.12it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:26<00:03,  1.12it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:26<00:03,  1.12it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:26<00:03,  1.12it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.11it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.11it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.11it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.11it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.13it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.13it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.13it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.13it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.17it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.17it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.17it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.17it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.20it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.19it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.19it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.19it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]
  Batch 0: Grad norm = 0.161191
  Batch 10: Grad norm = 0.219458
  Batch 20: Grad norm = 0.195432
Train Loss: 1.464439, Cosine Sim: 0.1951

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9900, log_space=4.5901, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9900)!

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.161191
  Batch 10: Grad norm = 0.219458
  Batch 20: Grad norm = 0.195432
  Batch 0: Grad norm = 0.161191
  Batch 10: Grad norm = 0.219458
  Batch 20: Grad norm = 0.195432
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.161191
  Batch 10: Grad norm = 0.219458
  Batch 20: Grad norm = 0.195432
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  4.99s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.01s/it]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.05s/it]/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.14s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.14s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.33s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.28s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.31s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.19it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.69s/it]
Val Loss: 1.808320, Cosine Sim: 0.0776, MSE: 1.8083
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 10/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:47,  5.79s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:47,  5.79s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:47,  5.79s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:47,  5.78s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.86s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.86s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.86s/it]Training:   7%|â–‹         | 2/30 [00:06<01:19,  2.85s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.92s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.92s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.92s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.92s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.51s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.51s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.51s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.51s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:28,  1.20s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:28,  1.20s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:28,  1.20s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:28,  1.20s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:25,  1.11s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:25,  1.11s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:25,  1.11s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:25,  1.11s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.03s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.03s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.03s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.03s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.06it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.06it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.06it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.06it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.02it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.02it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.02it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.02it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.08it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.08it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.08it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.08it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.11it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.11it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.11it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.11it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:14,  1.16it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:14,  1.16it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:14,  1.16it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:14,  1.16it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:13,  1.15it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:13,  1.15it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:13,  1.15it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:13,  1.15it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.12it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.12it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.12it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.18it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.18it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.18it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.18it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.20it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.20it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.20it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.20it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.21it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.21it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.21it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.21it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.16it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.16it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.16it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.16it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.10it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.10it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.10it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.10it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:07,  1.12it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:07,  1.12it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:07,  1.12it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:07,  1.12it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.13it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.13it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.13it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.13it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.20it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.20it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.20it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.20it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.13it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.13it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.13it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.13it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.12it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.12it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.12it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.12it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.14it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.14it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.14it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.14it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.14it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.14it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.14it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.14it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:30<00:00,  1.16it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:30<00:00,  1.16it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:30<00:00,  1.16it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:30<00:00,  1.16it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.22it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.22it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.21it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.21it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.07s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.07s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.07s/it]
  Batch 0: Grad norm = 0.276642
  Batch 10: Grad norm = 0.376013
  Batch 20: Grad norm = 0.537063

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.07s/it]
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.276642
  Batch 10: Grad norm = 0.376013
  Batch 20: Grad norm = 0.537063
  Batch 0: Grad norm = 0.276642
  Batch 10: Grad norm = 0.376013
  Batch 20: Grad norm = 0.537063
Train Loss: 1.469776, Cosine Sim: 0.1878

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9899, log_space=4.5899, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9899)!
  Batch 0: Grad norm = 0.276642
  Batch 10: Grad norm = 0.376013
  Batch 20: Grad norm = 0.537063
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  4.99s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.01s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.00s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.01s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.14s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.15s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.15s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.22s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.27it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.61s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Val Loss: 1.802635, Cosine Sim: 0.0729, MSE: 1.8026
Learning Rate: 2.00e-04
Saved checkpoint to models/ablation_non_multi_hop/checkpoint_epoch_10.pt
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 11/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:41,  5.58s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:41,  5.59s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:41,  5.59s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:41,  5.59s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.80s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.80s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.80s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.80s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.91s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.91s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.91s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.91s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.52s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.52s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.52s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.52s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.16s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.17s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.17s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.17s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.03s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.03s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.03s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.03s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.05it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.05it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.05it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.05it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.11it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.11it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.11it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.11it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.10it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.10it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.10it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.10it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.11it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.11it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.11it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.11it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.08it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.08it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.08it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.08it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:15,  1.10it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:15,  1.10it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:15,  1.10it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:15,  1.10it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:15,  1.04it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:15,  1.04it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:15,  1.04it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:15,  1.04it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:14,  1.04it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:14,  1.04it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:14,  1.04it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:14,  1.04it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:13,  1.06it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:13,  1.06it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:13,  1.06it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:13,  1.06it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:12,  1.08it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:12,  1.08it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:12,  1.08it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:12,  1.08it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:11,  1.02it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:11,  1.02it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:11,  1.02it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:11,  1.02it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:10,  1.06it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:10,  1.06it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:10,  1.06it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:10,  1.06it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:09,  1.05it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:09,  1.05it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:09,  1.05it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:09,  1.04it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.03it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.03it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.03it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.03it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:07,  1.08it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:07,  1.08it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:07,  1.08it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:07,  1.08it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:25<00:06,  1.13it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:25<00:06,  1.13it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:25<00:06,  1.13it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:25<00:06,  1.13it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:26<00:05,  1.14it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:26<00:05,  1.14it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:26<00:05,  1.14it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:26<00:05,  1.14it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:27<00:04,  1.11it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:27<00:04,  1.11it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:27<00:04,  1.11it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:27<00:04,  1.11it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:28<00:03,  1.14it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:28<00:03,  1.14it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:28<00:03,  1.14it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:28<00:03,  1.14it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.13it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.13it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.13it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.13it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.15it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.15it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.15it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.15it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:30<00:00,  1.18it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:30<00:00,  1.18it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:30<00:00,  1.18it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:30<00:00,  1.18it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.18it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.18it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.18it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.18it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:32<00:00,  1.08s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:32<00:00,  1.08s/it]  Batch 0: Grad norm = 0.251490
  Batch 10: Grad norm = 0.222690
  Batch 20: Grad norm = 0.290471
Train Loss: 1.415824, Cosine Sim: 0.2006

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9899, log_space=4.5893, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9899)!

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:32<00:00,  1.08s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:32<00:00,  1.08s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.251490
  Batch 10: Grad norm = 0.222690
  Batch 20: Grad norm = 0.290471
  Batch 0: Grad norm = 0.251490
  Batch 10: Grad norm = 0.222690
  Batch 20: Grad norm = 0.290471
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.251490
  Batch 10: Grad norm = 0.222690
  Batch 20: Grad norm = 0.290471
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  4.98s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.02s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.01s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.03s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.14s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.15s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.14s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.15s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.22s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.27it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.61s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Val Loss: 1.769439, Cosine Sim: 0.0779, MSE: 1.7694
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 12/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:53,  5.97s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:53,  5.97s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:53,  5.97s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:53,  5.97s/it]Training:   7%|â–‹         | 2/30 [00:06<01:22,  2.94s/it]Training:   7%|â–‹         | 2/30 [00:06<01:22,  2.94s/it]Training:   7%|â–‹         | 2/30 [00:06<01:22,  2.94s/it]Training:   7%|â–‹         | 2/30 [00:06<01:22,  2.94s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:53,  1.98s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:53,  1.98s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:53,  1.98s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:53,  1.98s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.50s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.50s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.50s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.50s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:31,  1.25s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:31,  1.25s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:31,  1.25s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:31,  1.25s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.15s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.15s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.15s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.15s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.02s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.02s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.02s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.02s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.06it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.06it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.06it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.06it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.09it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.09it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.09it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.09it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.03it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.03it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.03it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.03it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.06it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.06it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.06it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.06it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.10it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.10it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.10it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.10it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:16,  1.05it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:16,  1.05it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:16,  1.05it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:16,  1.05it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:14,  1.07it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:14,  1.07it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:14,  1.07it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:14,  1.07it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.10it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.10it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.09it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.09it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.14it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.14it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.14it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.15it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.14it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.18it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.18it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.18it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.18it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.16it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.16it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.16it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.16it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.16it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.16it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.16it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.16it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.12it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.12it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.12it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.12it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:06,  1.20it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:06,  1.20it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:06,  1.20it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:06,  1.20it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.27it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.27it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.27it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.27it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.22it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.22it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.22it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.22it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.21it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.21it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.21it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.21it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.19it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.19it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.19it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.19it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.08it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.08it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.08it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.08it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.11it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.11it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.11it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.11it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:30<00:00,  1.15it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:30<00:00,  1.15it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:30<00:00,  1.15it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.17it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.17it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.16it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.16it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.07s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.07s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.07s/it]
  Batch 0: Grad norm = 0.233343
  Batch 10: Grad norm = 0.268276
  Batch 20: Grad norm = 0.461578
Train Loss: 1.395865, Cosine Sim: 0.1935

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9899, log_space=4.5884, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9899)!

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.07s/it]
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.233343
  Batch 10: Grad norm = 0.268276
  Batch 20: Grad norm = 0.461578
  Batch 0: Grad norm = 0.233343
  Batch 10: Grad norm = 0.268276
  Batch 20: Grad norm = 0.461578
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.233343
  Batch 10: Grad norm = 0.268276
  Batch 20: Grad norm = 0.461578
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  5.00s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.03s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.03s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.03s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.15s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.14s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.15s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]

Val Loss: 1.758770, Cosine Sim: 0.0729, MSE: 1.7588
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 13/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:49,  5.84s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:49,  5.84s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:49,  5.84s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:49,  5.84s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.88s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.88s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.88s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.88s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.49s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.49s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.49s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.49s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:31,  1.24s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:31,  1.25s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:31,  1.25s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:31,  1.25s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:26,  1.09s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:26,  1.09s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:26,  1.09s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:26,  1.10s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.07s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.07s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.07s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.07s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.00s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.00s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.00s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.00s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.07it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.07it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.07it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.07it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.06it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.06it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.06it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.06it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.06it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.06it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.06it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.06it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:17,  1.04it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:17,  1.04it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:17,  1.04it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:17,  1.04it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.08it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.08it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.08it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.08it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:14,  1.13it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:14,  1.13it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:14,  1.13it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:14,  1.13it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.15it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.15it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.15it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.15it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.15it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.15it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.15it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.15it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.15it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.15it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.15it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.15it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.21it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.21it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.21it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.21it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.14it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.14it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.13it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.13it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.11it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.11it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.11it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.11it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:07,  1.10it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:07,  1.10it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:07,  1.10it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:07,  1.10it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:25<00:06,  1.09it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:25<00:06,  1.09it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:25<00:06,  1.09it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:25<00:06,  1.09it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.12it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.12it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.12it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.12it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.06it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.05it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.05it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.05it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.08it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.08it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.08it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.08it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.14it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.14it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.14it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.14it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.18it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.18it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.18it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.18it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:30<00:00,  1.17it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:30<00:00,  1.17it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:30<00:00,  1.17it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:30<00:00,  1.17it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.20it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.20it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.20it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.20it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:32<00:00,  1.07s/it]
  Batch 0: Grad norm = 0.703466
  Batch 10: Grad norm = 0.255693
  Batch 20: Grad norm = 0.137800
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:32<00:00,  1.07s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:32<00:00,  1.07s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:32<00:00,  1.07s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.703466
  Batch 10: Grad norm = 0.255693
  Batch 20: Grad norm = 0.137800
Train Loss: 1.340674, Cosine Sim: 0.2009

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9899, log_space=4.5883, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9899)!
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.703466
  Batch 10: Grad norm = 0.255693
  Batch 20: Grad norm = 0.137800
  Batch 0: Grad norm = 0.703466
  Batch 10: Grad norm = 0.255693
  Batch 20: Grad norm = 0.137800
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.01s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.05s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.04s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.05s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.14s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.17s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.17s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.61s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]
Val Loss: 1.735206, Cosine Sim: 0.0761, MSE: 1.7352
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 14/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:45,  5.71s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:45,  5.71s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:45,  5.71s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:45,  5.71s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.81s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.81s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.81s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.81s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.93s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.47s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.47s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.47s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.47s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.22s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.23s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.23s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:30,  1.23s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.14s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.14s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.14s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.14s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.03s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.03s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.03s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.03s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.04it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.04it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.04it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.04it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.08it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.08it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.08it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.08it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.02it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.02it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.02it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.02it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.12it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.12it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.12it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.12it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.18it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.18it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.18it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.18it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.18it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.18it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.18it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.18it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.16it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.16it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.16it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.16it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.12it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.12it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:12,  1.05it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:12,  1.05it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:12,  1.05it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:12,  1.05it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:11,  1.03it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:11,  1.03it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:11,  1.03it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:11,  1.03it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:10,  1.07it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:10,  1.07it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:10,  1.07it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:10,  1.07it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:09,  1.09it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:09,  1.09it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:09,  1.09it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:09,  1.09it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.12it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.12it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.12it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.12it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.18it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.18it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.18it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.18it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.21it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.21it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.21it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.21it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.22it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.22it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.22it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.22it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.19it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.19it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.19it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.19it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.20it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.20it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.20it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.20it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.20it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.20it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.20it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.20it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.17it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.17it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.17it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.17it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.19it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.19it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.19it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.19it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.09it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.09it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.09it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.09it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.07s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.07s/it]

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.07s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.07s/it]
  Batch 0: Grad norm = 0.201512
  Batch 10: Grad norm = 0.330198
  Batch 20: Grad norm = 0.243065

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.201512
  Batch 10: Grad norm = 0.330198
  Batch 20: Grad norm = 0.243065
  Batch 0: Grad norm = 0.201512
  Batch 10: Grad norm = 0.330198
  Batch 20: Grad norm = 0.243065
  Batch 0: Grad norm = 0.201512
  Batch 10: Grad norm = 0.330198
  Batch 20: Grad norm = 0.243065
Train Loss: 1.394845, Cosine Sim: 0.1993

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9899, log_space=4.5869, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9899)!
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.10s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.16s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.16s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.18s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.18s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.21s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.21s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.22s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.26s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.27s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.28s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.24it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.23it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.22it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.22it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.64s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.66s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.66s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.66s/it]
Val Loss: 1.724543, Cosine Sim: 0.0771, MSE: 1.7245
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 15/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:46,  5.74s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:46,  5.74s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:46,  5.74s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:46,  5.74s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.86s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.86s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.86s/it]Training:   7%|â–‹         | 2/30 [00:06<01:20,  2.86s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:54,  2.01s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:54,  2.01s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:54,  2.01s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:54,  2.01s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.52s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.52s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.52s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.52s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:31,  1.27s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:31,  1.27s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:31,  1.27s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:31,  1.27s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:26,  1.09s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:26,  1.09s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:26,  1.09s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:26,  1.09s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.04s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.04s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.04s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.04s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.05it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.05it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.05it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:20,  1.05it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.12it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.12it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.12it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:18,  1.12it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.13it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.13it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.13it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.13it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:16,  1.14it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:16,  1.14it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:16,  1.14it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:16,  1.14it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.12it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.12it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.12it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.12it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.19it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.19it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.19it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.19it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.20it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.20it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.20it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.20it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.19it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.19it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.19it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.19it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:11,  1.19it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:11,  1.19it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:11,  1.19it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:11,  1.19it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.16it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.16it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.16it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.16it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.09it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.09it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.09it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.09it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.12it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.12it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.12it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.12it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.14it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.14it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.14it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.14it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.16it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.16it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.16it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.16it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.16it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.16it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.16it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.16it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.21it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.21it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.21it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.21it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.20it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.20it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.20it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.20it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:26<00:03,  1.22it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:26<00:03,  1.22it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:26<00:03,  1.22it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:26<00:03,  1.22it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.21it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.21it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.21it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.21it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.23it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.23it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.23it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.23it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.27it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.27it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.27it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.27it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.24it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.24it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.24it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.24it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]
  Batch 0: Grad norm = 0.172509
  Batch 10: Grad norm = 0.202892
  Batch 20: Grad norm = 0.144198
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.04s/it]

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.172509
  Batch 10: Grad norm = 0.202892
  Batch 20: Grad norm = 0.144198
  Batch 0: Grad norm = 0.172509
  Batch 10: Grad norm = 0.202892
  Batch 20: Grad norm = 0.144198
  Batch 0: Grad norm = 0.172509
  Batch 10: Grad norm = 0.202892
  Batch 20: Grad norm = 0.144198
Train Loss: 1.374998, Cosine Sim: 0.2073

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9899, log_space=4.5872, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9899)!
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.12s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.14s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.16s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.15s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.20s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.19s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.21s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.21s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.26s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.27s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.27s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.24it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.23it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.23it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.23it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.64s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.65s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.65s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.66s/it]

Val Loss: 1.697438, Cosine Sim: 0.0783, MSE: 1.6974
Learning Rate: 2.00e-04
Saved checkpoint to models/ablation_non_multi_hop/checkpoint_epoch_15.pt
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 16/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:53,  5.98s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:53,  5.98s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:53,  5.99s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:53,  5.99s/it]Training:   7%|â–‹         | 2/30 [00:06<01:21,  2.91s/it]Training:   7%|â–‹         | 2/30 [00:06<01:21,  2.91s/it]Training:   7%|â–‹         | 2/30 [00:06<01:21,  2.91s/it]Training:   7%|â–‹         | 2/30 [00:06<01:21,  2.91s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.93s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:51,  1.93s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.52s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.52s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.52s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:39,  1.52s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.29s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.14s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.15s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.14s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.15s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:25,  1.12s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:25,  1.12s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:25,  1.12s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:11<00:25,  1.12s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.01s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.01s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.01s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:22,  1.01s/it]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.06it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.06it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.06it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.06it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.12it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.12it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.12it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:17,  1.12it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.12it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.12it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.12it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.12it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.11it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.11it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.11it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.11it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.07it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.07it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.07it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.07it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:14,  1.09it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:14,  1.09it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:14,  1.09it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:17<00:14,  1.09it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.11it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.11it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.11it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:18<00:13,  1.11it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.16it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.16it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.16it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.16it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.15it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.16it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.16it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.15it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.15it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.15it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.15it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.15it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.15it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.15it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.15it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.15it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:09,  1.10it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:09,  1.09it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:09,  1.09it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:09,  1.09it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.12it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.12it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.12it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.12it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:06,  1.17it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:06,  1.17it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:06,  1.17it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:24<00:06,  1.17it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.20it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.20it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.20it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.20it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.22it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.22it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.22it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:04,  1.22it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.17it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.17it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.17it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.17it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.14it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.14it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.14it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.14it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.21it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.21it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.21it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.21it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.24it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.24it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.24it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:29<00:01,  1.24it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.28it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.28it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.28it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.28it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.17it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.17it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.17it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.17it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]
  Batch 0: Grad norm = 0.266994
  Batch 10: Grad norm = 0.231158
  Batch 20: Grad norm = 0.464220

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.266994
  Batch 10: Grad norm = 0.231158
  Batch 20: Grad norm = 0.464220
  Batch 0: Grad norm = 0.266994
  Batch 10: Grad norm = 0.231158
  Batch 20: Grad norm = 0.464220
Train Loss: 1.302650, Cosine Sim: 0.2071

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9899, log_space=4.5871, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9899)!
  Batch 0: Grad norm = 0.266994
  Batch 10: Grad norm = 0.231158
  Batch 20: Grad norm = 0.464220
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.04s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.05s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.07s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.07s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.16s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.17s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.17s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.24s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.24it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.64s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.64s/it]
Val Loss: 1.691745, Cosine Sim: 0.0733, MSE: 1.6917
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 17/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:42,  5.60s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:42,  5.60s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:42,  5.60s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:42,  5.60s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.77s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.77s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.77s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.77s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:50,  1.87s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:50,  1.87s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:50,  1.87s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:50,  1.87s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:07<00:36,  1.42s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:07<00:36,  1.42s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:07<00:36,  1.42s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:07<00:36,  1.42s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:31,  1.26s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:31,  1.26s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:31,  1.26s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:31,  1.26s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.16s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.16s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.16s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:27,  1.16s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.08s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.08s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.08s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:24,  1.08s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.05it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.05it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.05it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.05it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.05it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.05it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.05it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.05it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.07it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.07it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.07it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.07it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.11it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.10it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.10it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.10it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.17it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.17it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.17it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.17it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.19it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.19it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.19it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.19it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.15it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.15it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.15it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.15it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.16it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.16it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.16it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.16it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.15it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.15it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.15it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.15it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.12it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.12it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.12it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.12it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.10it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.10it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.10it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:09,  1.10it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:09,  1.07it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:09,  1.07it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:09,  1.07it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:09,  1.07it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.09it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.09it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.09it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:23<00:08,  1.09it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.15it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.16it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.15it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.15it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.20it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.20it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.20it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:05,  1.20it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.14it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.14it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.14it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.14it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.11it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.11it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.11it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.11it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.18it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.18it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.18it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.18it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.15it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.15it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.15it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:28<00:02,  1.15it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.17it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.17it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.17it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.17it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.21it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.21it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.21it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.21it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]  Batch 0: Grad norm = 0.162926
  Batch 10: Grad norm = 0.184786
  Batch 20: Grad norm = 0.293281

Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.162926
  Batch 10: Grad norm = 0.184786
  Batch 20: Grad norm = 0.293281
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.06s/it]
  Batch 0: Grad norm = 0.162926
  Batch 10: Grad norm = 0.184786
  Batch 20: Grad norm = 0.293281
Train Loss: 1.306875, Cosine Sim: 0.2085

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9899, log_space=4.5863, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9899)!
  Batch 0: Grad norm = 0.162926
  Batch 10: Grad norm = 0.184786
  Batch 20: Grad norm = 0.293281
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  5.00s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.07s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.11s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.14s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.14s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.19s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.18s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.20s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.26s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.27s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.23it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.23it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.61s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.66s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.65s/it]
Val Loss: 1.671399, Cosine Sim: 0.0750, MSE: 1.6714
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 18/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:44,  5.67s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:44,  5.67s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:44,  5.67s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:44,  5.67s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.78s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.78s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.78s/it]Training:   7%|â–‹         | 2/30 [00:06<01:17,  2.78s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:50,  1.88s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:50,  1.88s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:50,  1.88s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:50,  1.88s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:37,  1.44s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:37,  1.44s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:37,  1.44s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:37,  1.44s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:31,  1.25s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:31,  1.25s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:31,  1.25s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:08<00:31,  1.25s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:26,  1.09s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:26,  1.09s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:26,  1.09s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:09<00:26,  1.09s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:22,  1.01it/s]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:22,  1.01it/s]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:22,  1.01it/s]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:22,  1.01it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.03it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.03it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.03it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.03it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:20,  1.04it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:20,  1.04it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:20,  1.04it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:20,  1.04it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.07it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.07it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.06it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:18,  1.06it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.08it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.08it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.08it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.08it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.14it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.14it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.14it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:14<00:15,  1.14it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.19it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.20it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.20it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:15<00:14,  1.19it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.23it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.23it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.23it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.23it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.21it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.20it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.20it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:12,  1.20it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:11,  1.24it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:11,  1.24it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:11,  1.24it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:11,  1.24it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:18<00:10,  1.24it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:18<00:10,  1.24it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:18<00:10,  1.24it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:18<00:10,  1.24it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:19<00:09,  1.24it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:19<00:09,  1.24it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:19<00:09,  1.24it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:19<00:09,  1.24it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.21it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.21it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.21it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:20<00:09,  1.21it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.12it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.12it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.12it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:21<00:08,  1.12it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:08,  1.07it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:08,  1.07it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:08,  1.07it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:08,  1.07it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:07,  1.08it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:07,  1.08it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:07,  1.08it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:07,  1.08it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.11it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.11it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.11it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.11it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.11it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.11it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.11it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.11it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.08it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.08it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.08it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.08it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.13it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.13it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.13it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.13it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.11it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.11it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.11it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:27<00:02,  1.11it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.17it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.17it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.17it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:28<00:01,  1.17it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.13it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.13it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.13it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [00:29<00:00,  1.13it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:30<00:00,  1.15it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]
  Batch 0: Grad norm = 0.132113
  Batch 10: Grad norm = 0.289267
  Batch 20: Grad norm = 0.144628

Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:31<00:00,  1.05s/it]
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.132113
  Batch 10: Grad norm = 0.289267
  Batch 20: Grad norm = 0.144628
  Batch 0: Grad norm = 0.132113
  Batch 10: Grad norm = 0.289267
  Batch 20: Grad norm = 0.144628
Train Loss: 1.344323, Cosine Sim: 0.1949

  ðŸ“Š Learnable Weights Monitoring:
    Nonbonded: weight=0.9899, log_space=4.5863, grad=N/A
    âš ï¸  WARNING: Nonbonded weight is very high (0.9899)!
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]  Batch 0: Grad norm = 0.132113
  Batch 10: Grad norm = 0.289267
  Batch 20: Grad norm = 0.144628
Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  4.97s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  4.96s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:04<00:14,  4.96s/it]Evaluating:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:05<00:15,  5.07s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.13s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.14s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.12s/it]Evaluating:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:05<00:04,  2.17s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.22s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.22s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.23s/it]Evaluating:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.25s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.27it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.27it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.27it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.25it/s]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.61s/it]
Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.61s/it]Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.61s/it]

Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.63s/it]
Val Loss: 1.658819, Cosine Sim: 0.0721, MSE: 1.6588
Learning Rate: 2.00e-04
New best model! Saved to models/ablation_non_multi_hop/best_model.pt

Epoch 19/300
------------------------------------------------------------
Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]Training:   0%|          | 0/30 [00:00<?, ?it/s]/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v3.py:63: UserWarning: layers/ module not found. Using basic implementations.
  warnings.warn("layers/ module not found. Using basic implementations.")
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/models/e3_gnn_encoder_v2.py:41: UserWarning: Improved layers not found. Using basic implementation. Install missing dependencies or check layers/ directory.
  warnings.warn(
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
/personal/RNA-3E-FFI/scripts/04_train_model.py:191: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.y = torch.tensor(ligand_embedding, dtype=torch.float32)
Training:   3%|â–Ž         | 1/30 [00:05<02:45,  5.69s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:45,  5.69s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:45,  5.69s/it]Training:   3%|â–Ž         | 1/30 [00:05<02:45,  5.69s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.80s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.80s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.80s/it]Training:   7%|â–‹         | 2/30 [00:06<01:18,  2.80s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.95s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.95s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.95s/it]Training:  10%|â–ˆ         | 3/30 [00:07<00:52,  1.95s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.49s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.49s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.49s/it]Training:  13%|â–ˆâ–Ž        | 4/30 [00:08<00:38,  1.49s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:31,  1.28s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.28s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.28s/it]Training:  17%|â–ˆâ–‹        | 5/30 [00:09<00:32,  1.28s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.16s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.16s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.16s/it]Training:  20%|â–ˆâ–ˆ        | 6/30 [00:10<00:27,  1.16s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.03s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.04s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.03s/it]Training:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:10<00:23,  1.04s/it]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:11<00:21,  1.01it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.07it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.07it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.07it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:12<00:19,  1.07it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.03it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.03it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.03it/s]Training:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:13<00:19,  1.03it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:14<00:17,  1.10it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.11it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.11it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.11it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:15<00:16,  1.11it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.11it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.11it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.11it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:16<00:15,  1.11it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.21it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.21it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.21it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:16<00:13,  1.21it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.14it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.13it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.13it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:17<00:13,  1.13it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.11it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.11it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.11it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:18<00:12,  1.11it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.09it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.09it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.09it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:19<00:11,  1.09it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.13it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.13it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.13it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:20<00:10,  1.13it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:08,  1.22it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:08,  1.22it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:08,  1.22it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:21<00:08,  1.22it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.20it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.20it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.20it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:22<00:08,  1.20it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.22it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.22it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.22it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:22<00:07,  1.22it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.18it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.18it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.18it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:23<00:06,  1.18it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.14it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.14it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.14it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:24<00:06,  1.14it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.15it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.15it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.15it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [00:25<00:05,  1.15it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.15it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.15it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.15it/s]Training:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [00:26<00:04,  1.15it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.15it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.15it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.15it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:27<00:03,  1.15it/s]W1111 23:11:32.070000 515293 site-packages/torch/multiprocessing/spawn.py:160] Terminating process 515382 via signal SIGTERM
W1111 23:11:32.071000 515293 site-packages/torch/multiprocessing/spawn.py:160] Terminating process 515384 via signal SIGTERM
W1111 23:11:32.083000 515293 site-packages/torch/multiprocessing/spawn.py:160] Terminating process 515385 via signal SIGTERM
Traceback (most recent call last):
  File "/personal/RNA-3E-FFI/scripts/04_train_model.py", line 1461, in <module>
    main()
  File "/personal/RNA-3E-FFI/scripts/04_train_model.py", line 1448, in main
    mp.spawn(
  File "/opt/mamba/envs/RNA/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 328, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/mamba/envs/RNA/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 284, in start_processes
    while not context.join():
              ^^^^^^^^^^^^^^
  File "/opt/mamba/envs/RNA/lib/python3.11/site-packages/torch/multiprocessing/spawn.py", line 184, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 1 terminated with signal SIGTERM
/opt/mamba/envs/RNA/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
